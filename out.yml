NAME: my-sketchbench
LAST DEPLOYED: Sat Jul 10 00:32:47 2021
NAMESPACE: default
STATUS: pending-install
REVISION: 1
USER-SUPPLIED VALUES:
bullet:
  enabled: true
  sparkBackend:
    config:
      bullet:
        dsl:
          connector:
            class:
              name: com.yahoo.bullet.dsl.connector.KafkaConnector
            kafka:
              bootstrap:
                servers: kafka:9092
              topics:
              - sketchbench-test
          converter:
            class:
              name: com.yahoo.bullet.dsl.converter.JSONBulletRecordConverter
            schema:
              type:
                check:
                  enable: false
          deserializer:
            class:
              name: com.yahoo.bullet.dsl.deserializer.IdentityDeserializer
        spark:
          dsl:
            data:
              producer:
                enable: true
            deserializer:
              enable: false
    dsl:
      schema: |
        {
          "fields": [
            {
              "name": "SketchBenchMessageID",
              "type": "INTEGER"
            },
            {
              "name": "SketchBenchBoolean",
              "type": "BOOLEAN"
            },
            {
              "name": "SketchBenchInteger",
              "type": "INTEGER"
            },
            {
              "name": "SketchBenchLong",
              "type": "LONG"
            },
            {
              "name": "SketchBenchFloat",
              "type": "FLOAT"
            },
            {
              "name": "SketchBenchDouble",
              "type": "DOUBLE"
            },
            {
              "name": "SketchBenchString",
              "type": "STRING"
            },
            {
              "name": "SketchBenchBooleanMap",
              "type": "BOOLEAN_MAP"
            },
            {
              "name": "SketchBenchIntegerMap",
              "type": "INTEGER_MAP"
            },
            {
              "name": "SketchBenchLongMap",
              "type": "LONG_MAP"
            },
            {
              "name": "SketchBenchFloatMap",
              "type": "FLOAT_MAP"
            },
            {
              "name": "SketchBenchDoubleMap",
              "type": "DOUBLE_MAP"
            },
            {
              "name": "SketchBenchStringMap",
              "type": "STRING_MAP"
            },
            {
              "name": "SketchBenchBooleanMapMap",
              "type": "BOOLEAN_MAP_MAP"
            },
            {
              "name": "SketchBenchIntegerMapMap",
              "type": "INTEGER_MAP_MAP"
            },
            {
              "name": "SketchBenchLongMapMap",
              "type": "LONG_MAP_MAP"
            },
            {
              "name": "SketchBenchFloatMapMap",
              "type": "FLOAT_MAP_MAP"
            },
            {
              "name": "SketchBenchDoubleMapMap",
              "type": "DOUBLE_MAP_MAP"
            },
            {
              "name": "SketchBenchStringMapMap",
              "type": "STRING_MAP_MAP"
            },
            {
              "name": "SketchBenchBooleanList",
              "type": "BOOLEAN_LIST"
            },
            {
              "name": "SketchBenchIntegerList",
              "type": "INTEGER_LIST"
            },
            {
              "name": "SketchBenchLongList",
              "type": "LONG_LIST"
            },
            {
              "name": "SketchBenchFloatList",
              "type": "FLOAT_LIST"
            },
            {
              "name": "SketchBenchDoubleList",
              "type": "DOUBLE_LIST"
            },
            {
              "name": "SketchBenchStringList",
              "type": "STRING_LIST"
            },
            {
              "name": "SketchBenchBooleanMapList",
              "type": "BOOLEAN_MAP_LIST"
            },
            {
              "name": "SketchBenchIntegerMapList",
              "type": "INTEGER_MAP_LIST"
            },
            {
              "name": "SketchBenchLongMapList",
              "type": "LONG_MAP_LIST"
            },
            {
              "name": "SketchBenchFloatMapList",
              "type": "FLOAT_MAP_LIST"
            },
            {
              "name": "SketchBenchDoubleMapList",
              "type": "DOUBLE_MAP_LIST"
            },
            {
              "name": "SketchBenchStringMapList",
              "type": "STRING_MAP_LIST"
            }
          ]
        }
dataIngestion:
  tester:
    enabled: true

COMPUTED VALUES:
bullet:
  enabled: true
  global:
    commonAnnotations: {}
    commonLabels: {}
    imagePullSecrets: []
  hdfs:
    antiAffinity: soft
    conf:
      hdfsSite:
        dfs.replication: 3
    dataNode:
      pdbMinAvailable: 3
      replicas: 3
      resources:
        limits:
          cpu: 1000m
          memory: 2048Mi
        requests:
          cpu: 10m
          memory: 256Mi
    enabled: true
    global:
      commonAnnotations: {}
      commonLabels: {}
      imagePullSecrets: []
    httpfs:
      adminPort: 14001
      port: 14000
    image:
      pullPolicy: IfNotPresent
      repository: gradiant/hdfs
      tag: 2.7.7
    ingress:
      dataNode:
        annotations: {}
        enabled: false
        hosts:
        - hdfs-datanode.local
        labels: {}
        path: /
      httpfs:
        annotations: {}
        enabled: false
        hosts:
        - httpfs.local
        labels: {}
        path: /
      nameNode:
        annotations: {}
        enabled: false
        hosts:
        - hdfs-namenode.local
        labels: {}
        path: /
    nameNode:
      pdbMinAvailable: 1
      port: 8020
      resources:
        limits:
          cpu: 1000m
          memory: 2048Mi
        requests:
          cpu: 10m
          memory: 256Mi
    persistence:
      dataNode:
        accessMode: ReadWriteOnce
        enabled: false
        size: 200Gi
      nameNode:
        accessMode: ReadWriteOnce
        enabled: false
        size: 50Gi
    prometheus:
      exporter:
        enabled: true
        image: marcelmay/hadoop-hdfs-fsimage-exporter:1.2
        port: 5556
  pubsub:
    advertisedListeners: []
    affinity: {}
    allowPlaintextListener: true
    annotations: {}
    args: []
    auth:
      clientProtocol: plaintext
      interBrokerProtocol: plaintext
      jaas:
        clientPasswords: []
        clientUsers:
        - user
        existingSecret: ""
        interBrokerPassword: ""
        interBrokerUser: admin
        zookeeperPassword: ""
        zookeeperUser: ""
      jksKeystoreSAN: ""
      jksPassword: ""
      jksSecret: ""
      jksTruststore: ""
      jksTruststoreSecret: ""
      sasl:
        interBrokerMechanism: plain
        jaas:
          clientPasswords: []
          clientUsers:
          - user
          existingSecret: ""
          interBrokerPassword: ""
          interBrokerUser: admin
          zookeeperPassword: ""
          zookeeperUser: ""
        mechanisms: plain,scram-sha-256,scram-sha-512
      saslInterBrokerMechanism: plain
      saslMechanisms: plain,scram-sha-256,scram-sha-512
      tls:
        autoGenerated: false
        endpointIdentificationAlgorithm: https
        existingSecret: ""
        jksKeystoreSAN: ""
        jksTruststore: ""
        jksTruststoreSecret: ""
        password: ""
        type: jks
      tlsEndpointIdentificationAlgorithm: https
    autoCreateTopicsEnable: true
    clusterDomain: cluster.local
    command:
    - /scripts/setup.sh
    common:
      exampleValue: common-chart
      global:
        commonAnnotations: {}
        commonLabels: {}
        imagePullSecrets: []
        imageRegistry: null
        storageClass: null
    commonAnnotations: {}
    commonLabels: {}
    config: null
    containerSecurityContext: {}
    customLivenessProbe: {}
    customReadinessProbe: {}
    defaultReplicationFactor: 1
    deleteTopicEnable: false
    existingConfigmap: null
    existingLog4jConfigMap: null
    externalAccess:
      autoDiscovery:
        enabled: false
        image:
          pullPolicy: IfNotPresent
          pullSecrets: []
          registry: docker.io
          repository: bitnami/kubectl
          tag: 1.19.12-debian-10-r5
        resources:
          limits: {}
          requests: {}
      enabled: false
      service:
        annotations: {}
        loadBalancerIPs: []
        loadBalancerSourceRanges: []
        nodePorts: []
        port: 9094
        type: LoadBalancer
        useHostIPs: false
    externalPort: 9094
    externalZookeeper:
      servers: []
    extraDeploy: []
    extraEnvVars: []
    extraVolumeMounts: []
    extraVolumes: []
    fullnameOverride: null
    global:
      commonAnnotations: {}
      commonLabels: {}
      imagePullSecrets: []
      imageRegistry: null
      storageClass: null
    heapOpts: -Xmx1024m -Xms1024m
    hostAliases: []
    image:
      debug: false
      pullPolicy: IfNotPresent
      pullSecrets: []
      registry: docker.io
      repository: bitnami/kafka
      tag: 2.8.0-debian-10-r43
    initContainers: []
    interBrokerListenerName: INTERNAL
    internalPort: 9093
    listenerSecurityProtocolMap: null
    listeners: []
    livenessProbe:
      enabled: true
      initialDelaySeconds: 10
      timeoutSeconds: 5
    loadBalancerSourceRanges: []
    log4j: null
    logFlushIntervalMessages: _10000
    logFlushIntervalMs: 1000
    logPersistence:
      accessModes:
      - ReadWriteOnce
      annotations: {}
      enabled: false
      mountPath: /opt/bitnami/kafka/logs
      selector: {}
      size: 8Gi
    logRetentionBytes: _1073741824
    logRetentionCheckIntervalMs: 300000
    logRetentionHours: 168
    logSegmentBytes: _1073741824
    logsDirs: /bitnami/kafka/data
    maxMessageBytes: _1000012
    metrics:
      jmx:
        config: |-
          jmxUrl: service:jmx:rmi:///jndi/rmi://127.0.0.1:5555/jmxrmi
          lowercaseOutputName: true
          lowercaseOutputLabelNames: true
          ssl: false
          {{- if .Values.metrics.jmx.whitelistObjectNames }}
          whitelistObjectNames: ["{{ join "\",\"" .Values.metrics.jmx.whitelistObjectNames }}"]
          {{- end }}
        enabled: false
        image:
          pullPolicy: IfNotPresent
          pullSecrets: []
          registry: docker.io
          repository: bitnami/jmx-exporter
          tag: 0.15.0-debian-10-r135
        resources:
          limits: {}
          requests: {}
        service:
          annotations:
            prometheus.io/path: /
            prometheus.io/port: '{{ .Values.metrics.jmx.service.port }}'
            prometheus.io/scrape: "true"
          loadBalancerSourceRanges: []
          nodePort: ""
          port: 5556
          type: ClusterIP
        whitelistObjectNames:
        - kafka.controller:*
        - kafka.server:*
        - java.lang:*
        - kafka.network:*
        - kafka.log:*
      kafka:
        affinity: {}
        enabled: false
        extraFlags: {}
        image:
          pullPolicy: IfNotPresent
          pullSecrets: []
          registry: docker.io
          repository: bitnami/kafka-exporter
          tag: 1.3.1-debian-10-r30
        initContainers: {}
        nodeSelector: {}
        resources:
          limits: {}
          requests: {}
        service:
          annotations:
            prometheus.io/path: /metrics
            prometheus.io/port: '{{ .Values.metrics.kafka.service.port }}'
            prometheus.io/scrape: "true"
          loadBalancerSourceRanges: []
          nodePort: ""
          port: 9308
          type: ClusterIP
        tlsCaCert: ca-file
        tlsCert: cert-file
        tlsKey: key-file
        tolerations: []
      serviceMonitor:
        enabled: false
        metricRelabelings: []
        relabelings: []
    minBrokerId: 0
    nameOverride: null
    nodeAffinityPreset:
      key: ""
      type: ""
      values: []
    nodePorts:
      client: ""
      external: ""
    nodeSelector: {}
    numIoThreads: 8
    numNetworkThreads: 3
    numPartitions: 1
    numRecoveryThreadsPerDataDir: 1
    offsetsTopicReplicationFactor: 1
    pdb:
      create: false
      maxUnavailable: 1
    persistence:
      accessModes:
      - ReadWriteOnce
      annotations: {}
      enabled: true
      mountPath: /bitnami/kafka
      selector: {}
      size: 8Gi
    podAffinityPreset: ""
    podAnnotations: {}
    podAntiAffinityPreset: soft
    podLabels: {}
    podManagementPolicy: Parallel
    podSecurityContext:
      enabled: true
      fsGroup: 1001
      runAsUser: 1001
    port: 9092
    priorityClassName: ""
    provisioning:
      args: []
      command: []
      enabled: false
      image:
        debug: false
        pullPolicy: IfNotPresent
        pullSecrets: []
        registry: docker.io
        repository: bitnami/kafka
        tag: 2.8.0-debian-10-r42
      numPartitions: 1
      podAnnotations: {}
      replicationFactor: 1
      resources:
        limits: {}
        requests: {}
      topics: []
    rbac:
      create: false
    readinessProbe:
      enabled: true
      failureThreshold: 6
      initialDelaySeconds: 5
      timeoutSeconds: 5
    replicaCount: 1
    resources:
      limits: {}
      requests: {}
    rollingUpdatePartition: null
    schedulerName: null
    service:
      annotations: {}
      externalPort: 9094
      internalPort: 9093
      loadBalancerSourceRanges: []
      nodePorts:
        client: ""
        external: ""
      port: 9092
      type: ClusterIP
    serviceAccount:
      automountServiceAccountToken: true
      create: true
    sidecars: {}
    socketReceiveBufferBytes: 102400
    socketRequestMaxBytes: _104857600
    socketSendBufferBytes: 102400
    terminationGracePeriodSeconds: null
    tolerations: []
    transactionStateLogMinIsr: 1
    transactionStateLogReplicationFactor: 1
    type: ClusterIP
    updateStrategy: RollingUpdate
    volumePermissions:
      enabled: false
      image:
        pullPolicy: Always
        pullSecrets: []
        registry: docker.io
        repository: bitnami/bitnami-shell
        tag: 10-debian-10-r115
      resources:
        limits: {}
        requests: {}
      securityContext:
        runAsUser: 0
    zookeeper:
      affinity: {}
      allowAnonymousLogin: true
      auth:
        clientPassword: null
        clientUser: null
        enabled: false
        serverPasswords: null
        serverUsers: null
      autopurge:
        purgeInterval: 0
        snapRetainCount: 3
      clusterDomain: cluster.local
      common:
        exampleValue: common-chart
        global:
          commonAnnotations: {}
          commonLabels: {}
          imagePullSecrets: []
          imageRegistry: null
          storageClass: null
      commonAnnotations: {}
      commonLabels: {}
      customLivenessProbe: {}
      customReadinessProbe: {}
      dataLogDir: ""
      enabled: true
      extraDeploy: []
      fourlwCommandsWhitelist: srvr, mntr, ruok
      global:
        commonAnnotations: {}
        commonLabels: {}
        imagePullSecrets: []
        imageRegistry: null
        storageClass: null
      heapSize: 1024
      hostAliases: []
      image:
        debug: false
        pullPolicy: IfNotPresent
        registry: docker.io
        repository: bitnami/zookeeper
        tag: 3.7.0-debian-10-r68
      initContainers: []
      initLimit: 10
      listenOnAllIPs: false
      livenessProbe:
        enabled: true
        failureThreshold: 6
        initialDelaySeconds: 30
        periodSeconds: 10
        probeCommandTimeout: 2
        successThreshold: 1
        timeoutSeconds: 5
      logLevel: ERROR
      maxClientCnxns: 60
      maxSessionTimeout: 40000
      metrics:
        containerPort: 9141
        enabled: false
        prometheusRule:
          enabled: false
          rules: []
        service:
          annotations:
            prometheus.io/path: /metrics
            prometheus.io/port: '{{ .Values.metrics.service.port }}'
            prometheus.io/scrape: "true"
          port: 9141
          type: ClusterIP
        serviceMonitor:
          enabled: false
      minServerId: 1
      networkPolicy:
        enabled: false
      nodeAffinityPreset:
        key: ""
        type: ""
        values: []
      nodeSelector: {}
      persistence:
        accessModes:
        - ReadWriteOnce
        annotations: {}
        dataLogDir:
          selector: {}
          size: 8Gi
        enabled: true
        selector: {}
        size: 8Gi
      podAffinityPreset: ""
      podAnnotations: {}
      podAntiAffinityPreset: soft
      podDisruptionBudget:
        maxUnavailable: 1
      podLabels: {}
      podManagementPolicy: Parallel
      priorityClassName: ""
      readinessProbe:
        enabled: true
        failureThreshold: 6
        initialDelaySeconds: 5
        periodSeconds: 10
        probeCommandTimeout: 2
        successThreshold: 1
        timeoutSeconds: 5
      replicaCount: 1
      resources:
        requests:
          cpu: 250m
          memory: 256Mi
      securityContext:
        enabled: true
        fsGroup: 1001
        runAsUser: 1001
      service:
        annotations: {}
        disableBaseClientPort: false
        electionPort: 3888
        followerPort: 2888
        headless:
          annotations: {}
        nodePorts:
          client: ""
          clientTls: ""
        port: 2181
        publishNotReadyAddresses: true
        tlsClientPort: 3181
        type: ClusterIP
      serviceAccount:
        automountServiceAccountToken: true
        create: false
      syncLimit: 5
      tickTime: 2000
      tls:
        client:
          autoGenerated: false
          enabled: false
          keystorePassword: ""
          keystorePath: /opt/bitnami/zookeeper/config/certs/client/zookeeper.keystore.jks
          truststorePassword: ""
          truststorePath: /opt/bitnami/zookeeper/config/certs/client/zookeeper.truststore.jks
        quorum:
          autoGenerated: false
          keystorePassword: ""
          keystorePath: /opt/bitnami/zookeeper/config/certs/quorum/zookeeper.keystore.jks
          truststorePassword: ""
          truststorePath: /opt/bitnami/zookeeper/config/certs/quorum/zookeeper.truststore.jks
        resources:
          limits: {}
          requests: {}
      tolerations: []
      updateStrategy: RollingUpdate
      volumePermissions:
        enabled: false
        image:
          pullPolicy: Always
          registry: docker.io
          repository: bitnami/bitnami-shell
          tag: 10-debian-10-r111
        resources: {}
    zookeeperConnectionTimeoutMs: 6000
  pubsubMonit:
    autoscaling:
      annotations: {}
      apiVersion: ""
      behavior: {}
      enabled: true
      labels: {}
      metrics: []
    commonLabels: {}
    config:
      jvm:
      - -Xms128M
      - -Xmx256M
      - -Xss180K
      - -XX:-TieredCompilation
      - -XX:+UseStringDeduplication
      - -noverify
      kafka:
        connections:
        - pubsub:9092
        keystore:
          content: ""
          destination: kafka.keystore.jks
        properties:
          content: ""
          destination: kafka.properties
        truststore:
          content: ""
          destination: kafka.truststore.jks
      protoDesc:
        enabled: false
        files: []
        path: /proto-descriptors
      server:
        context: /
        port: "9000"
    deployment:
      affinity: {}
      apiVersion: ""
      args: {}
      command: {}
      containerFields: {}
      containerName: pubsub-monit
      deploymentExtras: {}
      environment: []
      forceRedeploy: false
      image:
        registry: docker.io
        repository: obsidiandynamics/kafdrop
      imagePullSecrets: []
      initContainers: []
      labels: {}
      lifecycle: {}
      livenessProbe:
        httpGet:
          path: '{{ include "kafdrop.endpoint" $ }}'
          port: http
        initialDelaySeconds: 60
      nodeSelector: {}
      podAnnotations: {}
      podFields: {}
      podLabels: {}
      podSecurityContext: {}
      ports: []
      priorityClassName: ""
      readinessProbe:
        httpGet:
          path: '{{ include "kafdrop.endpoint" $ }}'
          port: http
        initialDelaySeconds: 60
      replicaCount: 1
      resources: {}
      restartPolicy: null
      securityContext: {}
      selectorLabels: {}
      serviceAccount:
        annotations: {}
        apiVersion: ""
        automountServiceAccountToken: true
        create: false
        enabled: false
        globalPullSecrets: false
        imagePullSecrets: []
        labels: {}
        name: ""
        secrets: []
      sidecars: []
      startupProbe: {}
      strategy: {}
      tolerations: {}
      volumeMounts: []
      volumes: []
    enabled: true
    fullnameOverride: ""
    global:
      commonAnnotations: {}
      commonLabels: {}
      defaultTag: ""
      imagePullPolicy: ""
      imagePullSecrets: []
      imageRegistry: ""
      storageClass: ""
    ingress:
      annotations: {}
      apiVersion: ""
      backend: {}
      customRules: []
      enabled: true
      hosts: []
      ingressClass: ""
      labels: {}
      tls: []
    jmxExporter:
      args: {}
      command: {}
      config:
        lowercaseOutputLabelNames: true
        lowercaseOutputName: true
        ssl: false
      containerFields: {}
      enabled: false
      endpoint:
        interval: 10s
        path: /
        scrapeTimeout: 10s
      environment: {}
      image:
        registry: docker.io
        repository: bitnami/jmx-exporter
        tag: 0.13.0-debian-10-r52
      labels:
        app.kubernetes.io/component: metrics
      lifecycle: {}
      livenessProbe: {}
      name: jmx
      port: 5556
      ports: {}
      readinessProbe: {}
      resources: {}
      securityContext: {}
      service:
        annotations:
          prometheus.io/path: /
          prometheus.io/port: "5556"
          prometheus.io/scrape: "true"
        apiVersion: ""
        enabled: true
        extraPorts: []
        labels:
          app.kubernetes.io/component: metrics
          manifests.bedag/component: jmx
        loadBalancerIP: ""
        loadBalancerSourceRanges: []
        nodePort: ""
        portName: ""
        selector: {}
        targetPort: ""
        type: ClusterIP
      serviceMonitor:
        additonalFields: {}
        apiVersion: ""
        enabled: true
        endpoints: {}
        labels:
          app.kubernetes.io/component: metrics
          manifests.bedag/component: jmx
        namespace: ""
        namespaceSelector: []
        selector:
          app.kubernetes.io/instance: my-sketchbench
          app.kubernetes.io/name: pubsub-monit
          manifests.bedag/component: jmx
      startupProbe: {}
      targetPort: 5555
      volumeMounts: {}
    kubeCapabilities: ""
    manifests:
      global:
        commonAnnotations: {}
        commonLabels: {}
        defaultTag: ""
        imagePullPolicy: ""
        imagePullSecrets: []
        imageRegistry: ""
        storageClass: ""
      library:
        global:
          commonAnnotations: {}
          commonLabels: {}
          defaultTag: ""
          imagePullPolicy: ""
          imagePullSecrets: []
          imageRegistry: ""
          storageClass: ""
    nameOverride: pubsub-monit
    overwriteLabels: {}
    pdb:
      apiVersion: ""
      enabled: true
      labels: {}
      selectorLabels: {}
    proxy:
      httpProxy:
        host: ""
        protocol: ""
      httpsProxy:
        host: ""
        protocol: ""
      noProxy: []
    selectorLabels: {}
    service:
      annotations: {}
      apiVersion: ""
      enabled: true
      extraPorts: []
      labels: {}
      loadBalancerIP: ""
      loadBalancerSourceRanges: []
      nodePort: ""
      port: 9000
      portName: ""
      selector: {}
      targetPort: ""
      type: ClusterIP
    timezone: America/Los_Angeles
  spark:
    common:
      exampleValue: common-chart
      global:
        commonAnnotations: {}
        commonLabels: {}
        imagePullSecrets: []
    enabled: true
    extraDeploy: []
    global:
      commonAnnotations: {}
      commonLabels: {}
      imagePullSecrets: []
    hostNetwork: false
    image:
      debug: false
      pullPolicy: IfNotPresent
      registry: docker.io
      repository: sketchbench/bullet-spark
      tag: 1.0.4
    ingress:
      annotations: {}
      certManager: false
      enabled: false
      hostname: spark.local
      path: /
      pathType: ImplementationSpecific
      secrets: []
      tls: false
    kubeVersion: null
    master:
      affinity: {}
      clusterPort: 7077
      extraPodLabels: {}
      hostAliases: []
      initContainers: {}
      livenessProbe:
        enabled: true
        failureThreshold: 6
        initialDelaySeconds: 180
        periodSeconds: 20
        successThreshold: 1
        timeoutSeconds: 5
      nodeAffinityPreset:
        key: ""
        type: ""
        values: []
      nodeSelector: {}
      podAffinityPreset: ""
      podAnnotations: {}
      podAntiAffinityPreset: soft
      readinessProbe:
        enabled: true
        failureThreshold: 6
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources:
        limits: {}
        requests: {}
      securityContext:
        enabled: true
        fsGroup: 1001
        runAsGroup: 0
        runAsUser: 1001
        seLinuxOptions: {}
      tolerations: []
      webPort: 8080
    metrics:
      enabled: false
      masterAnnotations:
        prometheus.io/path: /metrics/
        prometheus.io/port: '{{ .Values.master.webPort }}'
        prometheus.io/scrape: "true"
      podMonitor:
        additionalLabels: {}
        enabled: false
        extraMetricsEndpoints: []
        interval: 30s
      prometheusRule:
        additionalLabels: {}
        enabled: false
        namespace: ""
        rules: []
      workerAnnotations:
        prometheus.io/path: /metrics/
        prometheus.io/port: '{{ .Values.worker.webPort }}'
        prometheus.io/scrape: "true"
    security:
      rpc:
        authenticationEnabled: false
        encryptionEnabled: false
      ssl:
        autoGenerated: false
        enabled: false
        needClientAuth: false
        protocol: TLSv1.2
        resources:
          limits: {}
          requests: {}
      storageEncryptionEnabled: false
    service:
      annotations: {}
      clusterPort: 7077
      nodePorts:
        cluster: ""
        web: ""
      type: ClusterIP
      webPort: 80
    worker:
      affinity: {}
      autoscaling:
        CpuTargetPercentage: 50
        enabled: false
        replicasMax: 5
      coreLimit: 3
      extraPodLabels: {}
      extraPorts: []
      hostAliases: []
      initContainers: {}
      livenessProbe:
        enabled: true
        failureThreshold: 6
        initialDelaySeconds: 180
        periodSeconds: 20
        successThreshold: 1
        timeoutSeconds: 5
      nodeAffinityPreset:
        key: ""
        type: ""
        values: []
      nodeSelector: {}
      podAffinityPreset: ""
      podAnnotations: {}
      podAntiAffinityPreset: soft
      podManagementPolicy: OrderedReady
      readinessProbe:
        enabled: true
        failureThreshold: 6
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      replicaCount: 3
      resources:
        limits: {}
        requests: {}
      securityContext:
        enabled: true
        fsGroup: 1001
        runAsGroup: 0
        runAsUser: 1001
        seLinuxOptions: {}
      tolerations: []
      webPort: 8081
  sparkBackend:
    affinity: {}
    cluster:
      affinity: {}
      clusterPort: 7077
      extraPodLabels: {}
      hostAliases: []
      initContainers: {}
      livenessProbe:
        enabled: true
        failureThreshold: 6
        initialDelaySeconds: 180
        periodSeconds: 20
        successThreshold: 1
        timeoutSeconds: 5
      nodeAffinityPreset:
        key: ""
        type: ""
        values: []
      nodeSelector: {}
      podAffinityPreset: ""
      podAnnotations: {}
      podAntiAffinityPreset: soft
      readinessProbe:
        enabled: true
        failureThreshold: 6
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources:
        limits: {}
        requests: {}
      securityContext:
        enabled: true
        fsGroup: 1001
        runAsGroup: 0
        runAsUser: 1001
        seLinuxOptions: {}
      tolerations: []
      webPort: 8080
    config:
      bullet:
        dsl:
          connector:
            async:
              commit:
                enable: true
            class:
              name: com.yahoo.bullet.dsl.connector.KafkaConnector
            kafka:
              bootstrap:
                servers: kafka:9092
              enable:
                auto:
                  commit: true
              group:
                id: bullet-consumer-group
              key:
                deserializer: org.apache.kafka.common.serialization.StringDeserializer
              start:
                at:
                  end:
                    enable: false
              topics:
              - sketchbench-test
              value:
                deserializer: org.apache.kafka.common.serialization.StringDeserializer
            read:
              timeout:
                ms: 0
          converter:
            class:
              name: com.yahoo.bullet.dsl.converter.JSONBulletRecordConverter
            schema:
              file: /bullet/schemas/dsl_schema.json
              type:
                check:
                  enable: false
          deserializer:
            class:
              name: com.yahoo.bullet.dsl.deserializer.IdentityDeserializer
        pubsub:
          class:
            name: com.yahoo.bullet.kafka.KafkaPubSub
          context:
            name: QUERY_PROCESSING
          kafka:
            request:
              topic:
                name: bullet.requests
            response:
              topic:
                name: bullet.responses
        query:
          aggregation:
            count:
              distinct:
                sketch:
                  entries: 16384
            distribution:
              generated:
                points:
                  rounding: 6
              max:
                points: 200
              sketch:
                entries: 1024
            group:
              sketch:
                entries: 1024
            raw:
              max:
                size: 500
            top:
              k:
                sketch:
                  entries: 1024
                  error:
                    type: NFN
        record:
          provider:
            class:
              name: com.yahoo.bullet.record.simple.UntypedSimpleBulletRecordProvider
        result:
          metadata:
            enable: true
        spark:
          app:
            name: BulletSparkStreamingJob
          batch:
            duration:
              ms: 1000
          checkpoint:
            dir: /spark/checkpoints
          data:
            producer:
              class:
                name: com.yahoo.bullet.spark.examples.RandomProducer
              parallelism: 1
          dsl:
            data:
              producer:
                enable: true
            deserializer:
              enable: false
          filter:
            partition:
              parallel:
                mode:
                  enabled: false
                  min:
                    query:
                      threshold: 10
                  parallelism: 4
          join:
            checkpoint:
              duration:
                multiplier: 10
          loop:
            pubsub:
              overrides: {}
          metrics:
            enabled: false
          query:
            union:
              checkpoint:
                duration:
                  multiplier: 10
          receiver:
            query:
              block:
                size: 1
              coalesce:
                partitions: 10
          recover:
            from:
              checkpoint:
                enable: false
      spark:
        closure:
          serializer: org.apache.spark.serializer.KryoSerializer
        serializer: org.apache.spark.serializer.KryoSerializer
        streaming:
          driver:
            writeAheadLog:
              allowBatching: false
          receiver:
            writeAheadLog:
              enable: false
          stopGracefullyOnShutdown: true
    configDir: /bullet/configs
    driver:
      blockManagerPort: 4042
      port: 4041
    dsl:
      schema: |
        {
          "fields": [
            {
              "name": "SketchBenchMessageID",
              "type": "INTEGER"
            },
            {
              "name": "SketchBenchBoolean",
              "type": "BOOLEAN"
            },
            {
              "name": "SketchBenchInteger",
              "type": "INTEGER"
            },
            {
              "name": "SketchBenchLong",
              "type": "LONG"
            },
            {
              "name": "SketchBenchFloat",
              "type": "FLOAT"
            },
            {
              "name": "SketchBenchDouble",
              "type": "DOUBLE"
            },
            {
              "name": "SketchBenchString",
              "type": "STRING"
            },
            {
              "name": "SketchBenchBooleanMap",
              "type": "BOOLEAN_MAP"
            },
            {
              "name": "SketchBenchIntegerMap",
              "type": "INTEGER_MAP"
            },
            {
              "name": "SketchBenchLongMap",
              "type": "LONG_MAP"
            },
            {
              "name": "SketchBenchFloatMap",
              "type": "FLOAT_MAP"
            },
            {
              "name": "SketchBenchDoubleMap",
              "type": "DOUBLE_MAP"
            },
            {
              "name": "SketchBenchStringMap",
              "type": "STRING_MAP"
            },
            {
              "name": "SketchBenchBooleanMapMap",
              "type": "BOOLEAN_MAP_MAP"
            },
            {
              "name": "SketchBenchIntegerMapMap",
              "type": "INTEGER_MAP_MAP"
            },
            {
              "name": "SketchBenchLongMapMap",
              "type": "LONG_MAP_MAP"
            },
            {
              "name": "SketchBenchFloatMapMap",
              "type": "FLOAT_MAP_MAP"
            },
            {
              "name": "SketchBenchDoubleMapMap",
              "type": "DOUBLE_MAP_MAP"
            },
            {
              "name": "SketchBenchStringMapMap",
              "type": "STRING_MAP_MAP"
            },
            {
              "name": "SketchBenchBooleanList",
              "type": "BOOLEAN_LIST"
            },
            {
              "name": "SketchBenchIntegerList",
              "type": "INTEGER_LIST"
            },
            {
              "name": "SketchBenchLongList",
              "type": "LONG_LIST"
            },
            {
              "name": "SketchBenchFloatList",
              "type": "FLOAT_LIST"
            },
            {
              "name": "SketchBenchDoubleList",
              "type": "DOUBLE_LIST"
            },
            {
              "name": "SketchBenchStringList",
              "type": "STRING_LIST"
            },
            {
              "name": "SketchBenchBooleanMapList",
              "type": "BOOLEAN_MAP_LIST"
            },
            {
              "name": "SketchBenchIntegerMapList",
              "type": "INTEGER_MAP_LIST"
            },
            {
              "name": "SketchBenchLongMapList",
              "type": "LONG_MAP_LIST"
            },
            {
              "name": "SketchBenchFloatMapList",
              "type": "FLOAT_MAP_LIST"
            },
            {
              "name": "SketchBenchDoubleMapList",
              "type": "DOUBLE_MAP_LIST"
            },
            {
              "name": "SketchBenchStringMapList",
              "type": "STRING_MAP_LIST"
            }
          ]
        }
    executorCores: 2
    executorMemory: 3G
    hdfs:
      pdbMinAvailable: 1
      port: 8020
      resources:
        limits:
          cpu: 1000m
          memory: 2048Mi
        requests:
          cpu: 10m
          memory: 256Mi
    hdfsUser: hdfs
    image:
      pullPolicy: IfNotPresent
      repository: sketchbench/bullet-spark
      tag: 1.0.4
    imagePullSecrets: []
    jar: /opt/bitnami/spark/jars/bullet-spark-standalone.jar
    nodeSelector: {}
    otherJars: /opt/bitnami/spark/jars/bullet-kafka-fat.jar,/opt/bitnami/spark/jars/bullet-dsl.jar,/opt/bitnami/spark/jars/bullet-spark-example.jar
    podAnnotations: {}
    podSecurityContext: {}
    resources: {}
    schemaDir: /bullet/schemas
    securityContext: {}
    service:
      port: 4040
      type: ClusterIP
    tolerations: []
  ui:
    affinity: {}
    autoscaling:
      enabled: false
    config:
      queryHost: http://localhost:9999
      schemaHost: http://localhost:9999
    configDir: /usr/local/var/bullet/ui/config
    image:
      pullPolicy: IfNotPresent
      repository: sketchbench/bullet-ui
      tag: 1.1.0
    nodeSelector: {}
    podAnnotations: {}
    podSecurityContext: {}
    replicaCount: 1
    resources: {}
    securityContext: {}
    service:
      port: 8800
      type: ClusterIP
    tolerations: []
  webservice:
    affinity: {}
    autoscaling:
      enabled: false
    config:
      bullet:
        pubsub:
          kafka:
            request:
              topic:
                name: bullet.requests
            response:
              topic:
                name: bullet.responses
        query:
          aggregation:
            max:
              size: 1024
    configDir: /bullet/configs
    image:
      pullPolicy: IfNotPresent
      repository: sketchbench/bullet-service
      tag: 1.1.0
    nodeSelector: {}
    podAnnotations: {}
    podSecurityContext: {}
    replicaCount: 1
    resources: {}
    securityContext: {}
    service:
      port: 9999
      type: ClusterIP
    tolerations: []
dataIngestion:
  espbench:
    acks: 1
    affinity: {}
    batchSize: 16384
    benchmarkRun: 1
    bufferMemorySize: 33554432
    duration: 5
    durationTimeUnit: MINUTES
    enabled: false
    image:
      pullPolicy: IfNotPresent
      repository: sketchbench/sketchbench-data-ingestion-espbench
      tag: 0.1.0
    initImage:
      pullPolicy: IfNotPresent
      repository: sketchbench/sketchbench-data-ingestion-espbench-init
      tag: 0.1.0
    jar: DataSender-assembly-0.1.0-SNAPSHOT.jar
    javaOpts: -Xms1g
    keySerializer: org.apache.kafka.common.serialization.StringSerializer
    lingerTime: 0
    nodeSelector: {}
    podAnnotations: {}
    podSecurityContext: {}
    readinRam: false
    replicaCount: 1
    resources: {}
    securityContext: {}
    sendingInterval: 10000
    sendingIntervalTimeUnit: NANOSECONDS
    tolerations: []
    topicPrefix: SketchBench
    valueSerializer: org.apache.kafka.common.serialization.StringSerializer
    verbose: true
  kafka:
    annotations: {}
    externalPort: 9094
    internalPort: 9093
    loadBalancerSourceRanges: []
    nodePorts:
      client: ""
      external: ""
    port: 9092
    type: ClusterIP
  tester:
    affinity: {}
    enabled: true
    image:
      pullPolicy: IfNotPresent
      repository: sketchbench/sketchbench-data-ingestion-tester
      tag: 1.0.1
    maxWaitingTime: 0.5
    nodeSelector: {}
    numberMessages: 0
    podAnnotations: {}
    podSecurityContext: {}
    replicaCount: 1
    resources: {}
    securityContext: {}
    tolerations: []
    topic: sketchbench-test
  zookeeper:
    annotations: {}
    disableBaseClientPort: false
    electionPort: 3888
    followerPort: 2888
    headless:
      annotations: {}
    nodePorts:
      client: ""
      clientTls: ""
    port: 2181
    publishNotReadyAddresses: true
    tlsClientPort: 3181
    type: ClusterIP
global:
  commonAnnotations: {}
  commonLabels: {}
  imagePullSecrets: []
kafdrop:
  autoscaling:
    annotations: {}
    apiVersion: ""
    behavior: {}
    enabled: true
    labels: {}
    metrics: []
  commonLabels: {}
  config:
    jvm:
    - -Xms128M
    - -Xmx256M
    - -Xss180K
    - -XX:-TieredCompilation
    - -XX:+UseStringDeduplication
    - -noverify
    kafka:
      connections:
      - kafka:9092
      keystore:
        content: ""
        destination: kafka.keystore.jks
      properties:
        content: ""
        destination: kafka.properties
      truststore:
        content: ""
        destination: kafka.truststore.jks
    protoDesc:
      enabled: false
      files: []
      path: /proto-descriptors
    server:
      context: /
      port: "9000"
  deployment:
    affinity: {}
    apiVersion: ""
    args: {}
    command: {}
    containerFields: {}
    deploymentExtras: {}
    environment: []
    forceRedeploy: false
    image:
      registry: docker.io
      repository: obsidiandynamics/kafdrop
    imagePullSecrets: []
    initContainers: []
    labels: {}
    lifecycle: {}
    livenessProbe:
      httpGet:
        path: '{{ include "kafdrop.endpoint" $ }}'
        port: http
      initialDelaySeconds: 60
    nodeSelector: {}
    podAnnotations: {}
    podFields: {}
    podLabels: {}
    podSecurityContext: {}
    ports: []
    priorityClassName: ""
    readinessProbe:
      httpGet:
        path: '{{ include "kafdrop.endpoint" $ }}'
        port: http
      initialDelaySeconds: 60
    replicaCount: 1
    resources: {}
    securityContext: {}
    selectorLabels: {}
    serviceAccount:
      annotations: {}
      apiVersion: ""
      automountServiceAccountToken: true
      create: false
      enabled: false
      globalPullSecrets: false
      imagePullSecrets: []
      labels: {}
      name: ""
      secrets: []
    sidecars: []
    startupProbe: {}
    strategy: {}
    tolerations: {}
    volumeMounts: []
    volumes: []
  fullnameOverride: ""
  global:
    commonAnnotations: {}
    commonLabels: {}
    defaultTag: ""
    imagePullPolicy: ""
    imagePullSecrets: []
    imageRegistry: ""
    storageClass: ""
  ingress:
    annotations: {}
    apiVersion: ""
    backend: {}
    customRules: []
    enabled: true
    hosts: []
    ingressClass: ""
    labels: {}
    tls: []
  jmxExporter:
    args: {}
    command: {}
    config:
      lowercaseOutputLabelNames: true
      lowercaseOutputName: true
      ssl: false
    containerFields: {}
    enabled: false
    endpoint:
      interval: 10s
      path: /
      scrapeTimeout: 10s
    environment: {}
    image:
      registry: docker.io
      repository: bitnami/jmx-exporter
      tag: 0.13.0-debian-10-r52
    labels:
      app.kubernetes.io/component: metrics
    lifecycle: {}
    livenessProbe: {}
    name: jmx
    port: 5556
    ports: {}
    readinessProbe: {}
    resources: {}
    securityContext: {}
    service:
      annotations:
        prometheus.io/path: /
        prometheus.io/port: "5556"
        prometheus.io/scrape: "true"
      apiVersion: ""
      enabled: true
      extraPorts: []
      labels:
        app.kubernetes.io/component: metrics
        manifests.bedag/component: jmx
      loadBalancerIP: ""
      loadBalancerSourceRanges: []
      nodePort: ""
      portName: ""
      selector: {}
      targetPort: ""
      type: ClusterIP
    serviceMonitor:
      additonalFields: {}
      apiVersion: ""
      enabled: true
      endpoints: {}
      labels:
        app.kubernetes.io/component: metrics
        manifests.bedag/component: jmx
      namespace: ""
      namespaceSelector: []
      selector:
        app.kubernetes.io/instance: my-sketchbench
        app.kubernetes.io/name: kafka-monit
        manifests.bedag/component: jmx
    startupProbe: {}
    targetPort: 5555
    volumeMounts: {}
  kubeCapabilities: ""
  manifests:
    global:
      commonAnnotations: {}
      commonLabels: {}
      defaultTag: ""
      imagePullPolicy: ""
      imagePullSecrets: []
      imageRegistry: ""
      storageClass: ""
    library:
      global:
        commonAnnotations: {}
        commonLabels: {}
        defaultTag: ""
        imagePullPolicy: ""
        imagePullSecrets: []
        imageRegistry: ""
        storageClass: ""
  nameOverride: kafka-monit
  overwriteLabels: {}
  pdb:
    apiVersion: ""
    enabled: true
    labels: {}
    selectorLabels: {}
  proxy:
    httpProxy:
      host: ""
      protocol: ""
    httpsProxy:
      host: ""
      protocol: ""
    noProxy: []
  selectorLabels: {}
  service:
    annotations: {}
    apiVersion: ""
    enabled: true
    extraPorts: []
    labels: {}
    loadBalancerIP: ""
    loadBalancerSourceRanges: []
    nodePort: ""
    port: 9000
    portName: ""
    selector: {}
    targetPort: ""
    type: ClusterIP
  timezone: America/Los_Angeles
kafka:
  advertisedListeners: []
  affinity: {}
  allowPlaintextListener: true
  args: []
  auth:
    clientProtocol: plaintext
    interBrokerProtocol: plaintext
    jaas:
      clientPasswords: []
      clientUsers:
      - user
      existingSecret: ""
      interBrokerPassword: ""
      interBrokerUser: admin
      zookeeperPassword: ""
      zookeeperUser: ""
    jksKeystoreSAN: ""
    jksPassword: ""
    jksSecret: ""
    jksTruststore: ""
    jksTruststoreSecret: ""
    sasl:
      interBrokerMechanism: plain
      jaas:
        clientPasswords: []
        clientUsers:
        - user
        existingSecret: ""
        interBrokerPassword: ""
        interBrokerUser: admin
        zookeeperPassword: ""
        zookeeperUser: ""
      mechanisms: plain,scram-sha-256,scram-sha-512
    saslInterBrokerMechanism: plain
    saslMechanisms: plain,scram-sha-256,scram-sha-512
    tls:
      autoGenerated: false
      endpointIdentificationAlgorithm: https
      existingSecret: ""
      jksKeystoreSAN: ""
      jksTruststore: ""
      jksTruststoreSecret: ""
      password: ""
      type: jks
    tlsEndpointIdentificationAlgorithm: https
  autoCreateTopicsEnable: true
  clusterDomain: cluster.local
  command:
  - /scripts/setup.sh
  common:
    exampleValue: common-chart
    global:
      commonAnnotations: {}
      commonLabels: {}
      imagePullSecrets: []
  commonAnnotations: {}
  commonLabels: {}
  containerSecurityContext: {}
  customLivenessProbe: {}
  customReadinessProbe: {}
  defaultReplicationFactor: 1
  deleteTopicEnable: false
  externalAccess:
    autoDiscovery:
      enabled: false
      image:
        pullPolicy: IfNotPresent
        pullSecrets: []
        registry: docker.io
        repository: bitnami/kubectl
        tag: 1.19.12-debian-10-r5
      resources:
        limits: {}
        requests: {}
    enabled: false
    service:
      annotations: {}
      loadBalancerIPs: []
      loadBalancerSourceRanges: []
      nodePorts: []
      port: 9094
      type: LoadBalancer
      useHostIPs: false
  externalZookeeper:
    servers: []
  extraDeploy: []
  extraEnvVars: []
  extraVolumeMounts: []
  extraVolumes: []
  global:
    commonAnnotations: {}
    commonLabels: {}
    imagePullSecrets: []
  heapOpts: -Xmx1024m -Xms1024m
  hostAliases: []
  image:
    debug: false
    pullPolicy: IfNotPresent
    pullSecrets: []
    registry: docker.io
    repository: bitnami/kafka
    tag: 2.8.0-debian-10-r43
  initContainers: []
  interBrokerListenerName: INTERNAL
  listeners: []
  livenessProbe:
    enabled: true
    initialDelaySeconds: 10
    timeoutSeconds: 5
  logFlushIntervalMessages: _10000
  logFlushIntervalMs: 1000
  logPersistence:
    accessModes:
    - ReadWriteOnce
    annotations: {}
    enabled: false
    mountPath: /opt/bitnami/kafka/logs
    selector: {}
    size: 8Gi
  logRetentionBytes: _1073741824
  logRetentionCheckIntervalMs: 300000
  logRetentionHours: 168
  logSegmentBytes: _1073741824
  logsDirs: /bitnami/kafka/data
  maxMessageBytes: _1000012
  metrics:
    jmx:
      config: |-
        jmxUrl: service:jmx:rmi:///jndi/rmi://127.0.0.1:5555/jmxrmi
        lowercaseOutputName: true
        lowercaseOutputLabelNames: true
        ssl: false
        {{- if .Values.metrics.jmx.whitelistObjectNames }}
        whitelistObjectNames: ["{{ join "\",\"" .Values.metrics.jmx.whitelistObjectNames }}"]
        {{- end }}
      enabled: false
      image:
        pullPolicy: IfNotPresent
        pullSecrets: []
        registry: docker.io
        repository: bitnami/jmx-exporter
        tag: 0.15.0-debian-10-r135
      resources:
        limits: {}
        requests: {}
      service:
        annotations:
          prometheus.io/path: /
          prometheus.io/port: '{{ .Values.metrics.jmx.service.port }}'
          prometheus.io/scrape: "true"
        loadBalancerSourceRanges: []
        nodePort: ""
        port: 5556
        type: ClusterIP
      whitelistObjectNames:
      - kafka.controller:*
      - kafka.server:*
      - java.lang:*
      - kafka.network:*
      - kafka.log:*
    kafka:
      affinity: {}
      enabled: false
      extraFlags: {}
      image:
        pullPolicy: IfNotPresent
        pullSecrets: []
        registry: docker.io
        repository: bitnami/kafka-exporter
        tag: 1.3.1-debian-10-r30
      initContainers: {}
      nodeSelector: {}
      resources:
        limits: {}
        requests: {}
      service:
        annotations:
          prometheus.io/path: /metrics
          prometheus.io/port: '{{ .Values.metrics.kafka.service.port }}'
          prometheus.io/scrape: "true"
        loadBalancerSourceRanges: []
        nodePort: ""
        port: 9308
        type: ClusterIP
      tlsCaCert: ca-file
      tlsCert: cert-file
      tlsKey: key-file
      tolerations: []
    serviceMonitor:
      enabled: false
  minBrokerId: 0
  nodeAffinityPreset:
    key: ""
    type: ""
    values: []
  nodeSelector: {}
  numIoThreads: 8
  numNetworkThreads: 3
  numPartitions: 1
  numRecoveryThreadsPerDataDir: 1
  offsetsTopicReplicationFactor: 1
  pdb:
    create: false
    maxUnavailable: 1
  persistence:
    accessModes:
    - ReadWriteOnce
    annotations: {}
    enabled: true
    mountPath: /bitnami/kafka
    selector: {}
    size: 8Gi
  podAffinityPreset: ""
  podAnnotations: {}
  podAntiAffinityPreset: soft
  podLabels: {}
  podManagementPolicy: Parallel
  podSecurityContext:
    enabled: true
    fsGroup: 1001
    runAsUser: 1001
  priorityClassName: ""
  provisioning:
    args: []
    command: []
    enabled: false
    image:
      debug: false
      pullPolicy: IfNotPresent
      pullSecrets: []
      registry: docker.io
      repository: bitnami/kafka
      tag: 2.8.0-debian-10-r42
    numPartitions: 1
    podAnnotations: {}
    replicationFactor: 1
    resources:
      limits: {}
      requests: {}
    topics: []
  rbac:
    create: false
  readinessProbe:
    enabled: true
    failureThreshold: 6
    initialDelaySeconds: 5
    timeoutSeconds: 5
  replicaCount: 1
  resources:
    limits: {}
    requests: {}
  service:
    annotations: {}
    externalPort: 9094
    internalPort: 9093
    loadBalancerSourceRanges: []
    nodePorts:
      client: ""
      external: ""
    port: 9092
    type: ClusterIP
  serviceAccount:
    automountServiceAccountToken: true
    create: true
  sidecars: {}
  socketReceiveBufferBytes: 102400
  socketRequestMaxBytes: _104857600
  socketSendBufferBytes: 102400
  tolerations: []
  transactionStateLogMinIsr: 1
  transactionStateLogReplicationFactor: 1
  updateStrategy: RollingUpdate
  volumePermissions:
    enabled: false
    image:
      pullPolicy: Always
      pullSecrets: []
      registry: docker.io
      repository: bitnami/bitnami-shell
      tag: 10-debian-10-r115
    resources:
      limits: {}
      requests: {}
    securityContext:
      runAsUser: 0
  zookeeper:
    affinity: {}
    allowAnonymousLogin: true
    auth:
      clientPassword: null
      clientUser: null
      enabled: false
      serverPasswords: null
      serverUsers: null
    autopurge:
      purgeInterval: 0
      snapRetainCount: 3
    clusterDomain: cluster.local
    common:
      exampleValue: common-chart
      global:
        commonAnnotations: {}
        commonLabels: {}
        imagePullSecrets: []
    commonAnnotations: {}
    commonLabels: {}
    customLivenessProbe: {}
    customReadinessProbe: {}
    dataLogDir: ""
    enabled: true
    extraDeploy: []
    fourlwCommandsWhitelist: srvr, mntr, ruok
    global:
      commonAnnotations: {}
      commonLabels: {}
      imagePullSecrets: []
    heapSize: 1024
    hostAliases: []
    image:
      debug: false
      pullPolicy: IfNotPresent
      registry: docker.io
      repository: bitnami/zookeeper
      tag: 3.7.0-debian-10-r68
    initContainers: []
    initLimit: 10
    listenOnAllIPs: false
    livenessProbe:
      enabled: true
      failureThreshold: 6
      initialDelaySeconds: 30
      periodSeconds: 10
      probeCommandTimeout: 2
      successThreshold: 1
      timeoutSeconds: 5
    logLevel: ERROR
    maxClientCnxns: 60
    maxSessionTimeout: 40000
    metrics:
      containerPort: 9141
      enabled: false
      prometheusRule:
        enabled: false
        rules: []
      service:
        annotations:
          prometheus.io/path: /metrics
          prometheus.io/port: '{{ .Values.metrics.service.port }}'
          prometheus.io/scrape: "true"
        port: 9141
        type: ClusterIP
      serviceMonitor:
        enabled: false
    minServerId: 1
    nameOverride: kafka-zookeeper
    networkPolicy:
      enabled: false
    nodeAffinityPreset:
      key: ""
      type: ""
      values: []
    nodeSelector: {}
    persistence:
      accessModes:
      - ReadWriteOnce
      annotations: {}
      dataLogDir:
        selector: {}
        size: 8Gi
      enabled: true
      selector: {}
      size: 8Gi
    podAffinityPreset: ""
    podAnnotations: {}
    podAntiAffinityPreset: soft
    podDisruptionBudget:
      maxUnavailable: 1
    podLabels: {}
    podManagementPolicy: Parallel
    priorityClassName: ""
    readinessProbe:
      enabled: true
      failureThreshold: 6
      initialDelaySeconds: 5
      periodSeconds: 10
      probeCommandTimeout: 2
      successThreshold: 1
      timeoutSeconds: 5
    replicaCount: 1
    resources:
      requests:
        cpu: 250m
        memory: 256Mi
    securityContext:
      enabled: true
      fsGroup: 1001
      runAsUser: 1001
    service:
      annotations: {}
      disableBaseClientPort: false
      electionPort: 3888
      followerPort: 2888
      headless:
        annotations: {}
      nodePorts:
        client: ""
        clientTls: ""
      port: 2181
      publishNotReadyAddresses: true
      tlsClientPort: 3181
      type: ClusterIP
    serviceAccount:
      automountServiceAccountToken: true
      create: false
    syncLimit: 5
    tickTime: 2000
    tls:
      client:
        autoGenerated: false
        enabled: false
        keystorePassword: ""
        keystorePath: /opt/bitnami/zookeeper/config/certs/client/zookeeper.keystore.jks
        truststorePassword: ""
        truststorePath: /opt/bitnami/zookeeper/config/certs/client/zookeeper.truststore.jks
      quorum:
        autoGenerated: false
        keystorePassword: ""
        keystorePath: /opt/bitnami/zookeeper/config/certs/quorum/zookeeper.keystore.jks
        truststorePassword: ""
        truststorePath: /opt/bitnami/zookeeper/config/certs/quorum/zookeeper.truststore.jks
      resources:
        limits: {}
        requests: {}
    tolerations: []
    updateStrategy: RollingUpdate
    volumePermissions:
      enabled: false
      image:
        pullPolicy: Always
        registry: docker.io
        repository: bitnami/bitnami-shell
        tag: 10-debian-10-r111
      resources: {}
  zookeeperConnectionTimeoutMs: 6000
spark:
  common:
    exampleValue: common-chart
    global:
      commonAnnotations: {}
      commonLabels: {}
      imagePullSecrets: []
  enabled: false
  extraDeploy: []
  global:
    commonAnnotations: {}
    commonLabels: {}
    imagePullSecrets: []
  hostNetwork: false
  image:
    debug: false
    pullPolicy: IfNotPresent
    registry: docker.io
    repository: sketchbench/sketchbench-spark
    tag: 3.0.2
  ingress:
    annotations: {}
    certManager: false
    enabled: false
    hostname: spark.local
    path: /
    pathType: ImplementationSpecific
    secrets: []
    tls: false
  master:
    affinity: {}
    clusterPort: 7077
    extraPodLabels: {}
    hostAliases: []
    initContainers: {}
    livenessProbe:
      enabled: true
      failureThreshold: 6
      initialDelaySeconds: 180
      periodSeconds: 20
      successThreshold: 1
      timeoutSeconds: 5
    nodeAffinityPreset:
      key: ""
      type: ""
      values: []
    nodeSelector: {}
    podAffinityPreset: ""
    podAnnotations: {}
    podAntiAffinityPreset: soft
    readinessProbe:
      enabled: true
      failureThreshold: 6
      initialDelaySeconds: 30
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 5
    resources:
      limits: {}
      requests: {}
    securityContext:
      enabled: true
      fsGroup: 1001
      runAsGroup: 0
      runAsUser: 1001
      seLinuxOptions: {}
    tolerations: []
    webPort: 8080
  metrics:
    enabled: false
    masterAnnotations:
      prometheus.io/path: /metrics/
      prometheus.io/port: '{{ .Values.master.webPort }}'
      prometheus.io/scrape: "true"
    podMonitor:
      additionalLabels: {}
      enabled: false
      extraMetricsEndpoints: []
      interval: 30s
    prometheusRule:
      additionalLabels: {}
      enabled: false
      namespace: ""
      rules: []
    workerAnnotations:
      prometheus.io/path: /metrics/
      prometheus.io/port: '{{ .Values.worker.webPort }}'
      prometheus.io/scrape: "true"
  security:
    rpc:
      authenticationEnabled: false
      encryptionEnabled: false
    ssl:
      autoGenerated: false
      enabled: false
      needClientAuth: false
      protocol: TLSv1.2
      resources:
        limits: {}
        requests: {}
    storageEncryptionEnabled: false
  service:
    annotations: {}
    clusterPort: 7077
    nodePorts:
      cluster: ""
      web: ""
    type: ClusterIP
    webPort: 80
  worker:
    affinity: {}
    autoscaling:
      CpuTargetPercentage: 50
      enabled: false
      replicasMax: 5
    coreLimit: 3
    extraPodLabels: {}
    extraPorts: []
    hostAliases: []
    initContainers: {}
    livenessProbe:
      enabled: true
      failureThreshold: 6
      initialDelaySeconds: 180
      periodSeconds: 20
      successThreshold: 1
      timeoutSeconds: 5
    nodeAffinityPreset:
      key: ""
      type: ""
      values: []
    nodeSelector: {}
    podAffinityPreset: ""
    podAnnotations: {}
    podAntiAffinityPreset: soft
    podManagementPolicy: OrderedReady
    readinessProbe:
      enabled: true
      failureThreshold: 6
      initialDelaySeconds: 30
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 5
    replicaCount: 3
    resources:
      limits: {}
      requests: {}
    securityContext:
      enabled: true
      fsGroup: 1001
      runAsGroup: 0
      runAsUser: 1001
      seLinuxOptions: {}
    tolerations: []
    webPort: 8081
tobs:
  cli: false
  enabled: false
  global:
    commonAnnotations: {}
    commonLabels: {}
    imagePullSecrets: []
  grafanaDBJob:
    resources: {}
  kube-prometheus-stack:
    additionalPrometheusRulesMap: {}
    alertmanager:
      alertmanagerSpec:
        additionalPeers: []
        affinity: {}
        alertmanagerConfigNamespaceSelector: {}
        alertmanagerConfigSelector: {}
        clusterAdvertiseAddress: false
        configMaps: []
        containers: []
        forceEnableClusterMode: false
        image:
          repository: quay.io/prometheus/alertmanager
          sha: ""
          tag: v0.21.0
        initContainers: []
        listenLocal: false
        logFormat: logfmt
        logLevel: info
        nodeSelector: {}
        paused: false
        podAntiAffinity: ""
        podAntiAffinityTopologyKey: kubernetes.io/hostname
        podMetadata: {}
        portName: web
        priorityClassName: ""
        replicas: 1
        resources: {}
        retention: 120h
        routePrefix: /
        secrets: []
        securityContext:
          fsGroup: 2000
          runAsGroup: 2000
          runAsNonRoot: true
          runAsUser: 1000
        storage: {}
        tolerations: []
        topologySpreadConstraints: []
        useExistingSecret: false
        volumeMounts: []
        volumes: []
      annotations: {}
      apiVersion: v2
      config:
        global:
          resolve_timeout: 5m
        receivers:
        - name: "null"
        route:
          group_by:
          - job
          group_interval: 5m
          group_wait: 30s
          receiver: "null"
          repeat_interval: 12h
          routes:
          - match:
              alertname: Watchdog
            receiver: "null"
        templates:
        - /etc/alertmanager/config/*.tmpl
      enabled: false
      ingress:
        annotations: {}
        enabled: false
        hosts: []
        labels: {}
        paths: []
        tls: []
      ingressPerReplica:
        annotations: {}
        enabled: false
        hostDomain: ""
        hostPrefix: ""
        labels: {}
        paths: []
        tlsSecretName: ""
        tlsSecretPerReplica:
          enabled: false
          prefix: alertmanager
      podDisruptionBudget:
        enabled: false
        maxUnavailable: ""
        minAvailable: 1
      secret:
        annotations: {}
      service:
        additionalPorts: []
        annotations: {}
        clusterIP: ""
        externalIPs: []
        labels: {}
        loadBalancerIP: ""
        loadBalancerSourceRanges: []
        nodePort: 30903
        port: 9093
        targetPort: 9093
        type: ClusterIP
      serviceAccount:
        annotations: {}
        create: true
        name: ""
      serviceMonitor:
        interval: ""
        metricRelabelings: []
        proxyUrl: ""
        relabelings: []
        scheme: ""
        selfMonitor: true
        tlsConfig: {}
      servicePerReplica:
        annotations: {}
        enabled: false
        loadBalancerSourceRanges: []
        nodePort: 30904
        port: 9093
        targetPort: 9093
        type: ClusterIP
      templateFiles: {}
      tplConfig: false
    commonLabels: {}
    coreDns:
      enabled: true
      service:
        port: 9153
        targetPort: 9153
      serviceMonitor:
        interval: ""
        metricRelabelings: []
        proxyUrl: ""
        relabelings: []
    defaultRules:
      additionalRuleLabels: {}
      annotations: {}
      appNamespacesTarget: .*
      create: true
      labels: {}
      rules:
        alertmanager: true
        etcd: true
        general: true
        k8s: true
        kubeApiserver: true
        kubeApiserverAvailability: true
        kubeApiserverError: true
        kubeApiserverSlos: true
        kubePrometheusGeneral: true
        kubePrometheusNodeAlerting: true
        kubePrometheusNodeRecording: true
        kubeScheduler: true
        kubeStateMetrics: true
        kubelet: true
        kubernetesAbsent: true
        kubernetesApps: true
        kubernetesResources: true
        kubernetesStorage: true
        kubernetesSystem: true
        network: true
        node: true
        prometheus: true
        prometheusOperator: true
        time: true
      runbookUrl: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#
    enabled: true
    fullnameOverride: tobs-kube-prometheus
    global:
      commonAnnotations: {}
      commonLabels: {}
      imagePullSecrets: []
      rbac:
        create: true
        pspAnnotations: {}
        pspEnabled: true
    grafana:
      additionalDataSources: []
      admin:
        existingSecret: ""
        passwordKey: admin-password
        userKey: admin-user
      adminPassword: ""
      adminUser: admin
      affinity: {}
      containerSecurityContext: {}
      dashboardProviders: {}
      dashboards: {}
      dashboardsConfigMaps: {}
      datasources: {}
      defaultDashboardsEnabled: true
      deploymentStrategy:
        type: RollingUpdate
      downloadDashboards:
        env: {}
        envFromSecret: ""
        resources: {}
      downloadDashboardsImage:
        pullPolicy: IfNotPresent
        repository: curlimages/curl
        sha: ""
        tag: 7.73.0
      enabled: true
      env: {}
      envFromSecret: '{{ .Release.Name }}-grafana-db'
      envRenderSecret: {}
      envValueFrom: {}
      extraConfigmapMounts: []
      extraContainerVolumes: []
      extraContainers: ""
      extraEmptyDirMounts: []
      extraExposePorts: []
      extraInitContainers: []
      extraLabels: {}
      extraSecretMounts: []
      extraVolumeMounts: []
      global:
        commonAnnotations: {}
        commonLabels: {}
        imagePullSecrets: []
        rbac:
          create: true
          pspAnnotations: {}
          pspEnabled: true
      grafana.ini:
        analytics:
          check_for_updates: true
        grafana_net:
          url: https://grafana.net
        log:
          mode: console
        paths:
          data: /var/lib/grafana/data
          logs: /var/log/grafana
          plugins: /var/lib/grafana/plugins
          provisioning: /etc/grafana/provisioning
      hostAliases: []
      image:
        pullPolicy: IfNotPresent
        repository: grafana/grafana
        sha: ""
        tag: 7.5.3
      imageRenderer:
        enabled: false
        env:
          HTTP_HOST: 0.0.0.0
        grafanaSubPath: ""
        hostAliases: []
        image:
          pullPolicy: Always
          repository: grafana/grafana-image-renderer
          sha: ""
          tag: latest
        networkPolicy:
          limitEgress: false
          limitIngress: true
        podPortName: http
        priorityClassName: ""
        replicas: 1
        resources: {}
        revisionHistoryLimit: 10
        securityContext: {}
        service:
          enabled: true
          port: 8081
          portName: http
          targetPort: 8081
        serviceAccountName: ""
      ingress:
        annotations: {}
        enabled: false
        extraPaths: []
        hosts: []
        labels: {}
        path: /
        pathType: Prefix
        tls: []
      initChownData:
        enabled: true
        image:
          pullPolicy: IfNotPresent
          repository: busybox
          sha: ""
          tag: 1.31.1
        resources: {}
      ldap:
        config: ""
        enabled: false
        existingSecret: ""
      livenessProbe:
        failureThreshold: 10
        httpGet:
          path: /api/health
          port: 3000
        initialDelaySeconds: 60
        timeoutSeconds: 30
      namespaceOverride: ""
      nodeSelector: {}
      notifiers: {}
      persistence:
        accessModes:
        - ReadWriteOnce
        enabled: false
        finalizers:
        - kubernetes.io/pvc-protection
        inMemory:
          enabled: false
        size: 10Gi
        type: pvc
      plugins: []
      podDisruptionBudget: {}
      podPortName: grafana
      prometheus:
        datasource:
          enabled: true
          url: http://{{ .Release.Name }}-promscale-connector.{{ .Release.Namespace
            }}.svc.cluster.local:9201
      rbac:
        create: true
        extraClusterRoleRules: []
        extraRoleRules: []
        namespaced: false
        pspEnabled: true
        pspUseAppArmor: true
      readinessProbe:
        httpGet:
          path: /api/health
          port: 3000
      replicas: 1
      resources: {}
      revisionHistoryLimit: 10
      securityContext:
        fsGroup: 472
        runAsGroup: 472
        runAsUser: 472
      service:
        annotations: {}
        enabled: true
        labels: {}
        port: 80
        portName: service
        targetPort: 3000
        type: ClusterIP
      serviceAccount:
        create: true
      serviceMonitor:
        enabled: false
        interval: ""
        labels: {}
        metricRelabelings: []
        path: /metrics
        relabelings: []
        scheme: http
        scrapeTimeout: 30s
        selfMonitor: true
        tlsConfig: {}
      sidecar:
        dashboards:
          SCProvider: true
          annotations: {}
          enabled: true
          files:
          - dashboards/k8s-cluster.json
          - dashboards/k8s-hardware.json
          folder: /tmp/dashboards
          label: grafana_dashboard
          multicluster: false
          provider:
            allowUiUpdates: false
            disableDelete: false
            folder: ""
            foldersFromFilesStructure: false
            name: sidecarProvider
            orgid: 1
            type: file
          resource: both
        datasources:
          annotations: {}
          createPrometheusReplicasDatasources: false
          defaultDatasourceEnabled: false
          enabled: true
          label: tobs_datasource
          labelValue: "true"
          resource: both
        enableUniqueFilenames: false
        image:
          repository: quay.io/kiwigrid/k8s-sidecar
          sha: ""
          tag: 1.10.7
        imagePullPolicy: IfNotPresent
        notifiers:
          enabled: false
          label: grafana_notifier
          resource: both
        resources: {}
      smtp:
        existingSecret: ""
        passwordKey: password
        userKey: user
      testFramework:
        enabled: true
        image: bats/bats
        imagePullPolicy: IfNotPresent
        securityContext: {}
        tag: v1.1.0
      timescale:
        adminPassSecret: '{{ .Release.Name }}-credentials'
        adminUser: postgres
        database:
          dbName: postgres
          enabled: true
          host: '{{ .Release.Name }}.{{ .Release.Namespace }}.svc.cluster.local'
          pass: grafanadb
          port: 5432
          schema: grafanadb
          sslMode: require
          user: grafanadb
        datasource:
          dbName: postgres
          enabled: true
          host: '{{ .Release.Name }}.{{ .Release.Namespace }}.svc.cluster.local'
          pass: grafana
          port: 5432
          sslMode: require
          user: grafana
      tolerations: []
    kube-state-metrics:
      affinity: {}
      autosharding:
        enabled: false
      collectors:
        certificatesigningrequests: true
        configmaps: true
        cronjobs: true
        daemonsets: true
        deployments: true
        endpoints: true
        horizontalpodautoscalers: true
        ingresses: true
        jobs: true
        limitranges: true
        mutatingwebhookconfigurations: true
        namespaces: true
        networkpolicies: true
        nodes: true
        persistentvolumeclaims: true
        persistentvolumes: true
        poddisruptionbudgets: true
        pods: true
        replicasets: true
        replicationcontrollers: true
        resourcequotas: true
        secrets: true
        services: true
        statefulsets: true
        storageclasses: true
        validatingwebhookconfigurations: true
        verticalpodautoscalers: false
        volumeattachments: true
      customLabels: {}
      extraArgs: []
      global:
        commonAnnotations: {}
        commonLabels: {}
        imagePullSecrets: []
        rbac:
          create: true
          pspAnnotations: {}
          pspEnabled: true
      hostNetwork: false
      image:
        pullPolicy: IfNotPresent
        repository: k8s.gcr.io/kube-state-metrics/kube-state-metrics
        tag: v1.9.8
      imagePullSecrets: []
      kubeTargetVersionOverride: ""
      kubeconfig:
        enabled: false
      namespaceOverride: ""
      nodeSelector: {}
      podAnnotations: {}
      podDisruptionBudget: {}
      podSecurityPolicy:
        additionalVolumes: []
        annotations: {}
        enabled: true
      prometheus:
        monitor:
          additionalLabels: {}
          enabled: false
          honorLabels: false
          namespace: ""
      prometheusScrape: false
      rbac:
        create: true
        useClusterRole: true
      replicas: 1
      resources: {}
      securityContext:
        enabled: true
        fsGroup: 65534
        runAsGroup: 65534
        runAsUser: 65534
      selfMonitor:
        enabled: false
      service:
        annotations: {}
        loadBalancerIP: ""
        nodePort: 0
        port: 8080
        type: ClusterIP
      serviceAccount:
        annotations: {}
        create: true
        imagePullSecrets: []
      tolerations: []
    kubeApiServer:
      enabled: true
      relabelings: []
      serviceMonitor:
        interval: ""
        jobLabel: component
        metricRelabelings: []
        proxyUrl: ""
        selector:
          matchLabels:
            component: apiserver
            provider: kubernetes
      tlsConfig:
        insecureSkipVerify: false
        serverName: kubernetes
    kubeControllerManager:
      enabled: true
      endpoints: []
      service:
        enabled: true
        port: 10252
        targetPort: 10252
      serviceMonitor:
        enabled: true
        https: false
        interval: ""
        metricRelabelings: []
        proxyUrl: ""
        relabelings: []
    kubeDns:
      enabled: false
      service:
        dnsmasq:
          port: 10054
          targetPort: 10054
        skydns:
          port: 10055
          targetPort: 10055
      serviceMonitor:
        dnsmasqMetricRelabelings: []
        dnsmasqRelabelings: []
        interval: ""
        metricRelabelings: []
        proxyUrl: ""
        relabelings: []
    kubeEtcd:
      enabled: true
      endpoints: []
      service:
        enabled: true
        port: 2379
        targetPort: 2379
      serviceMonitor:
        caFile: ""
        certFile: ""
        enabled: true
        insecureSkipVerify: false
        interval: ""
        keyFile: ""
        metricRelabelings: []
        proxyUrl: ""
        relabelings: []
        scheme: http
        serverName: ""
    kubeProxy:
      enabled: true
      endpoints: []
      service:
        enabled: true
        port: 10249
        targetPort: 10249
      serviceMonitor:
        enabled: true
        https: false
        interval: ""
        metricRelabelings: []
        proxyUrl: ""
        relabelings: []
    kubeScheduler:
      enabled: true
      endpoints: []
      service:
        enabled: true
        port: 10251
        targetPort: 10251
      serviceMonitor:
        enabled: true
        https: false
        interval: ""
        metricRelabelings: []
        proxyUrl: ""
        relabelings: []
    kubeStateMetrics:
      enabled: true
      serviceMonitor:
        interval: ""
        metricRelabelings: []
        namespaceOverride: ""
        proxyUrl: ""
        relabelings: []
        selectorOverride: {}
    kubeTargetVersionOverride: ""
    kubelet:
      enabled: true
      namespace: kube-system
      serviceMonitor:
        cAdvisor: true
        cAdvisorMetricRelabelings: []
        cAdvisorRelabelings:
        - sourceLabels:
          - __metrics_path__
          targetLabel: metrics_path
        https: true
        interval: ""
        metricRelabelings: []
        probes: true
        probesMetricRelabelings: []
        probesRelabelings:
        - sourceLabels:
          - __metrics_path__
          targetLabel: metrics_path
        proxyUrl: ""
        relabelings:
        - sourceLabels:
          - __metrics_path__
          targetLabel: metrics_path
        resource: false
        resourcePath: /metrics/resource/v1alpha1
        resourceRelabelings:
        - sourceLabels:
          - __metrics_path__
          targetLabel: metrics_path
    nameOverride: ""
    namespaceOverride: ""
    nodeExporter:
      enabled: true
      jobLabel: jobLabel
      serviceMonitor:
        interval: ""
        metricRelabelings: []
        proxyUrl: ""
        relabelings: []
        scrapeTimeout: ""
    prometheus:
      additionalPodMonitors: []
      additionalRulesForClusterRole: []
      additionalServiceMonitors: []
      annotations: {}
      enabled: true
      ingress:
        annotations: {}
        enabled: false
        hosts: []
        labels: {}
        paths: []
        tls: []
      ingressPerReplica:
        annotations: {}
        enabled: false
        hostDomain: ""
        hostPrefix: ""
        labels: {}
        paths: []
        tlsSecretName: ""
        tlsSecretPerReplica:
          enabled: false
          prefix: prometheus
      podDisruptionBudget:
        enabled: false
        maxUnavailable: ""
        minAvailable: 1
      podSecurityPolicy:
        allowedCapabilities: []
        allowedHostPaths: []
        volumes: []
      prometheusSpec:
        additionalAlertManagerConfigs: []
        additionalAlertRelabelConfigs: []
        additionalPrometheusSecretsAnnotations: {}
        additionalRemoteRead: []
        additionalRemoteWrite: []
        additionalScrapeConfigs:
        - job_name: kubernetes-service-endpoints
          kubernetes_sd_configs:
          - role: endpoints
          relabel_configs:
          - action: keep
            regex: true
            source_labels:
            - __meta_kubernetes_service_annotation_prometheus_io_scrape
          - action: replace
            regex: (https?)
            source_labels:
            - __meta_kubernetes_service_annotation_prometheus_io_scheme
            target_label: __scheme__
          - action: replace
            regex: (.+)
            source_labels:
            - __meta_kubernetes_service_annotation_prometheus_io_path
            target_label: __metrics_path__
          - action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            source_labels:
            - __address__
            - __meta_kubernetes_service_annotation_prometheus_io_port
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - action: replace
            source_labels:
            - __meta_kubernetes_namespace
            target_label: kubernetes_namespace
          - action: replace
            source_labels:
            - __meta_kubernetes_service_name
            target_label: kubernetes_name
          - action: replace
            source_labels:
            - __meta_kubernetes_pod_node_name
            target_label: kubernetes_node
        - job_name: kubernetes-service-endpoints-slow
          kubernetes_sd_configs:
          - role: endpoints
          relabel_configs:
          - action: keep
            regex: true
            source_labels:
            - __meta_kubernetes_service_annotation_prometheus_io_scrape_slow
          - action: replace
            regex: (https?)
            source_labels:
            - __meta_kubernetes_service_annotation_prometheus_io_scheme
            target_label: __scheme__
          - action: replace
            regex: (.+)
            source_labels:
            - __meta_kubernetes_service_annotation_prometheus_io_path
            target_label: __metrics_path__
          - action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            source_labels:
            - __address__
            - __meta_kubernetes_service_annotation_prometheus_io_port
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - action: replace
            source_labels:
            - __meta_kubernetes_namespace
            target_label: kubernetes_namespace
          - action: replace
            source_labels:
            - __meta_kubernetes_service_name
            target_label: kubernetes_name
          - action: replace
            source_labels:
            - __meta_kubernetes_pod_node_name
            target_label: kubernetes_node
          scrape_interval: 5m
          scrape_timeout: 30s
        - job_name: kubernetes-services
          kubernetes_sd_configs:
          - role: service
          metrics_path: /probe
          params:
            module:
            - http_2xx
          relabel_configs:
          - action: keep
            regex: true
            source_labels:
            - __meta_kubernetes_service_annotation_prometheus_io_probe
          - source_labels:
            - __address__
            target_label: __param_target
          - replacement: blackbox
            target_label: __address__
          - source_labels:
            - __param_target
            target_label: instance
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels:
            - __meta_kubernetes_namespace
            target_label: kubernetes_namespace
          - source_labels:
            - __meta_kubernetes_service_name
            target_label: kubernetes_name
        - job_name: kubernetes-pods
          kubernetes_sd_configs:
          - role: pod
          relabel_configs:
          - action: keep
            regex: true
            source_labels:
            - __meta_kubernetes_pod_annotation_prometheus_io_scrape
          - action: replace
            regex: (https?)
            source_labels:
            - __meta_kubernetes_pod_annotation_prometheus_io_scheme
            target_label: __scheme__
          - action: replace
            regex: (.+)
            source_labels:
            - __meta_kubernetes_pod_annotation_prometheus_io_path
            target_label: __metrics_path__
          - action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            source_labels:
            - __address__
            - __meta_kubernetes_pod_annotation_prometheus_io_port
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - action: replace
            source_labels:
            - __meta_kubernetes_namespace
            target_label: kubernetes_namespace
          - action: replace
            source_labels:
            - __meta_kubernetes_pod_name
            target_label: kubernetes_pod_name
          - action: drop
            regex: Pending|Succeeded|Failed
            source_labels:
            - __meta_kubernetes_pod_phase
        - job_name: kubernetes-pods-slow
          kubernetes_sd_configs:
          - role: pod
          relabel_configs:
          - action: keep
            regex: true
            source_labels:
            - __meta_kubernetes_pod_annotation_prometheus_io_scrape_slow
          - action: replace
            regex: (https?)
            source_labels:
            - __meta_kubernetes_pod_annotation_prometheus_io_scheme
            target_label: __scheme__
          - action: replace
            regex: (.+)
            source_labels:
            - __meta_kubernetes_pod_annotation_prometheus_io_path
            target_label: __metrics_path__
          - action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            source_labels:
            - __address__
            - __meta_kubernetes_pod_annotation_prometheus_io_port
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - action: replace
            source_labels:
            - __meta_kubernetes_namespace
            target_label: kubernetes_namespace
          - action: replace
            source_labels:
            - __meta_kubernetes_pod_name
            target_label: kubernetes_pod_name
          - action: drop
            regex: Pending|Succeeded|Failed
            source_labels:
            - __meta_kubernetes_pod_phase
          scrape_interval: 5m
          scrape_timeout: 30s
        additionalScrapeConfigsSecret: {}
        affinity: {}
        alertingEndpoints: []
        allowOverlappingBlocks: false
        apiserverConfig: {}
        arbitraryFSAccessThroughSMs: false
        configMaps: []
        containers: []
        disableCompaction: false
        enableAdminAPI: false
        enableFeatures: []
        enforcedNamespaceLabel: ""
        enforcedSampleLimit: false
        evaluationInterval: 1m
        externalLabels: {}
        externalUrl: ""
        ignoreNamespaceSelectors: false
        image:
          repository: quay.io/prometheus/prometheus
          sha: ""
          tag: v2.26.0
        initContainers: []
        listenLocal: false
        logFormat: logfmt
        logLevel: info
        nodeSelector: {}
        overrideHonorLabels: false
        overrideHonorTimestamps: false
        paused: false
        podAntiAffinity: ""
        podAntiAffinityTopologyKey: kubernetes.io/hostname
        podMetadata: {}
        podMonitorNamespaceSelector: {}
        podMonitorSelector: {}
        podMonitorSelectorNilUsesHelmValues: true
        portName: web
        priorityClassName: ""
        probeNamespaceSelector: {}
        probeSelector: {}
        probeSelectorNilUsesHelmValues: true
        prometheusExternalLabelName: ""
        prometheusExternalLabelNameClear: false
        prometheusRulesExcludedFromEnforce: []
        query: {}
        queryLogFile: false
        remoteRead:
        - readRecent: true
          url: http://{{ .Release.Name }}-promscale-connector.{{ .Release.Namespace
            }}.svc.cluster.local:9201/read
        remoteWrite:
        - url: http://{{ .Release.Name }}-promscale-connector.{{ .Release.Namespace
            }}.svc.cluster.local:9201/write
        remoteWriteDashboards: false
        replicaExternalLabelName: ""
        replicaExternalLabelNameClear: false
        replicas: 1
        resources: {}
        retention: 10d
        retentionSize: ""
        routePrefix: /
        ruleNamespaceSelector: {}
        ruleSelector: {}
        ruleSelectorNilUsesHelmValues: true
        scrapeInterval: 1m
        scrapeTimeout: 10s
        secrets: []
        securityContext:
          fsGroup: 2000
          runAsGroup: 2000
          runAsNonRoot: true
          runAsUser: 1000
        serviceMonitorNamespaceSelector: {}
        serviceMonitorSelector: {}
        serviceMonitorSelectorNilUsesHelmValues: true
        shards: 1
        storageSpec:
          disableMountSubPath: true
          volumeClaimTemplate:
            spec:
              accessModes:
              - ReadWriteOnce
              resources:
                requests:
                  storage: 8Gi
        thanos: {}
        tolerations: []
        topologySpreadConstraints: []
        volumeMounts: []
        volumes: []
        walCompression: false
      service:
        annotations: {}
        clusterIP: ""
        externalIPs: []
        labels: {}
        loadBalancerIP: ""
        loadBalancerSourceRanges: []
        nodePort: 30090
        port: 9090
        sessionAffinity: ""
        targetPort: 9090
        type: ClusterIP
      serviceAccount:
        annotations: {}
        create: true
        name: ""
      serviceMonitor:
        interval: ""
        metricRelabelings: []
        relabelings: []
        scheme: ""
        selfMonitor: true
        tlsConfig: {}
      servicePerReplica:
        annotations: {}
        enabled: false
        loadBalancerSourceRanges: []
        nodePort: 30091
        port: 9090
        targetPort: 9090
        type: ClusterIP
      thanosIngress:
        annotations: {}
        enabled: false
        hosts: []
        labels: {}
        nodePort: 30901
        paths: []
        servicePort: 10901
        tls: []
      thanosService:
        annotations: {}
        clusterIP: None
        enabled: false
        labels: {}
        nodePort: 30901
        port: 10901
        portName: grpc
        targetPort: grpc
        type: ClusterIP
    prometheus-node-exporter:
      affinity: {}
      configmaps: []
      containerSecurityContext: {}
      dnsConfig: {}
      endpoints: []
      extraArgs:
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
      extraHostVolumeMounts: []
      extraInitContainers: []
      global:
        commonAnnotations: {}
        commonLabels: {}
        imagePullSecrets: []
        rbac:
          create: true
          pspAnnotations: {}
          pspEnabled: true
      hostNetwork: true
      hostRootFsMount: false
      image:
        pullPolicy: IfNotPresent
        repository: quay.io/prometheus/node-exporter
        tag: v1.1.2
      namespaceOverride: ""
      nodeSelector: {}
      podAnnotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
      podLabels:
        jobLabel: node-exporter
      prometheus:
        monitor:
          additionalLabels: {}
          enabled: false
          namespace: ""
          relabelings: []
          scheme: http
          scrapeTimeout: 10s
          tlsConfig: {}
      rbac:
        create: true
        pspEnabled: true
      resources: {}
      secrets: []
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
      service:
        annotations:
          prometheus.io/scrape: "false"
        listenOnAllInterfaces: true
        port: 9100
        targetPort: 9100
        type: ClusterIP
      serviceAccount:
        annotations: {}
        create: true
        imagePullSecrets: []
      sidecarVolumeMount: []
      sidecars: []
      tolerations:
      - effect: NoSchedule
        operator: Exists
      updateStrategy:
        rollingUpdate:
          maxUnavailable: 1
        type: RollingUpdate
    prometheusOperator:
      admissionWebhooks:
        caBundle: ""
        certManager:
          enabled: false
        enabled: true
        failurePolicy: Fail
        patch:
          affinity: {}
          enabled: true
          image:
            pullPolicy: IfNotPresent
            repository: jettech/kube-webhook-certgen
            sha: ""
            tag: v1.5.0
          nodeSelector: {}
          podAnnotations: {}
          priorityClassName: ""
          resources: {}
          tolerations: []
      affinity: {}
      alertmanagerInstanceNamespaces: []
      configReloaderCpu: 100m
      configReloaderMemory: 50Mi
      denyNamespaces: []
      dnsConfig: {}
      enabled: true
      hostNetwork: false
      image:
        pullPolicy: IfNotPresent
        repository: quay.io/prometheus-operator/prometheus-operator
        sha: ""
        tag: v0.47.0
      kubeletService:
        enabled: true
        namespace: kube-system
      namespaces: {}
      nodeSelector: {}
      podAnnotations: {}
      podLabels: {}
      prometheusConfigReloaderImage:
        repository: quay.io/prometheus-operator/prometheus-config-reloader
        sha: ""
        tag: v0.47.0
      prometheusInstanceNamespaces: []
      resources: {}
      secretFieldSelector: ""
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
      service:
        additionalPorts: []
        annotations: {}
        clusterIP: ""
        externalIPs: []
        labels: {}
        loadBalancerIP: ""
        loadBalancerSourceRanges: []
        nodePort: 30080
        nodePortTls: 30443
        type: ClusterIP
      serviceAccount:
        create: true
        name: ""
      serviceMonitor:
        interval: ""
        metricRelabelings: []
        relabelings: []
        scrapeTimeout: ""
        selfMonitor: true
      thanosRulerInstanceNamespaces: []
      tls:
        enabled: true
        internalPort: 10250
        tlsMinVersion: VersionTLS13
      tolerations: []
  promlens:
    defaultPrometheusUrl: http://localhost:9201
    enabled: true
    image: promlabs/promlens:latest
    loadBalancer:
      enabled: false
  promscale:
    affinity: {}
    args: []
    connection:
      dbName: postgres
      host:
        nameTemplate: '{{ .Release.Name }}.{{ .Release.Namespace }}.svc.cluster.local'
      password:
        secretTemplate: '{{ .Release.Name }}-credentials'
        timescaleDBSuperUserKey: PATRONI_SUPERUSER_PASSWORD
      port: 5432
      sslMode: require
      uri:
        key: db-uri
      user: postgres
    enabled: true
    global:
      commonAnnotations: {}
      commonLabels: {}
      imagePullSecrets: []
    image: timescale/promscale:0.5.0
    imagePullPolicy: IfNotPresent
    maintenance:
      affinity: {}
      enabled: false
      failedJobsHistoryLimit: 1
      nodeSelector: {}
      resources: {}
      schedule: 0,30 * * * *
      startingDeadlineSeconds: 200
      successfulJobsHistoryLimit: 3
      tolerations: []
    nodeSelector: {}
    prometheus:
      annotations:
        prometheus.io/path: /metrics
        prometheus.io/port: "9201"
        prometheus.io/scrape: "true"
      enabled: true
    replicaCount: 1
    resources:
      requests:
        cpu: 1
        memory: 2Gi
    service:
      loadBalancer:
        annotations:
          service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: "4000"
        enabled: false
      port: 9201
    tolerations: []
    upgradeStrategy: Recreate
  timescaledb-single:
    affinity: {}
    affinityTemplate: |
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            topologyKey: "kubernetes.io/hostname"
            labelSelector:
              matchLabels:
                app: {{ template "timescaledb.fullname" . }}
                release: {{ .Release.Name | quote }}
                cluster-name: {{ template "clusterName" . }}
        - weight: 50
          podAffinityTerm:
            topologyKey: failure-domain.beta.kubernetes.io/zone
            labelSelector:
              matchLabels:
                app: {{ template "timescaledb.fullname" . }}
                release: {{ .Release.Name | quote }}
                cluster-name: {{ template "clusterName" . }}
    backup:
      enabled: false
      jobs:
      - name: full-weekly
        schedule: 12 02 * * 0
        type: full
      - name: incremental-daily
        schedule: 12 02 * * 1-6
        type: incr
      pgBackRest:
        compress-type: lz4
        process-max: 4
        repo1-cipher-type: none
        repo1-retention-diff: 2
        repo1-retention-full: 2
        repo1-s3-endpoint: s3.amazonaws.com
        repo1-s3-region: us-east-2
        repo1-type: s3
        start-fast: "y"
      pgBackRest:archive-get: {}
      pgBackRest:archive-push: {}
    bootstrapFromBackup:
      enabled: false
      secretName: pgbackrest-bootstrap
    callbacks: {}
    debug: {}
    enabled: true
    fullWalPrevention:
      checkFrequency: 30
      enabled: false
      thresholds:
        readOnlyFreeMB: 64
        readOnlyFreePercent: 5
        readWriteFreeMB: 128
        readWriteFreePercent: 8
    global:
      commonAnnotations: {}
      commonLabels: {}
      imagePullSecrets: []
    image:
      pullPolicy: Always
      repository: timescaledev/timescaledb-ha
      tag: pg12-ts2.1-latest
    loadBalancer:
      annotations:
        service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: "4000"
      enabled: false
      port: 5432
    nameOverride: timescaledb
    networkPolicy:
      enabled: false
      prometheusApp: prometheus
    nodeSelector: {}
    patroni:
      bootstrap:
        dcs:
          loop_wait: 10
          maximum_lag_on_failover: 33554432
          postgresql:
            parameters:
              archive_command: /etc/timescaledb/scripts/pgbackrest_archive.sh %p
              archive_mode: "on"
              archive_timeout: 1800s
              autovacuum_analyze_scale_factor: 0.02
              autovacuum_max_workers: 10
              autovacuum_naptime: 5s
              autovacuum_vacuum_cost_limit: 500
              autovacuum_vacuum_scale_factor: 0.05
              hot_standby: "on"
              log_autovacuum_min_duration: 1min
              log_checkpoints: "on"
              log_connections: "on"
              log_disconnections: "on"
              log_line_prefix: '%t [%p]: [%c-%l] %u@%d,app=%a [%e] '
              log_lock_waits: "on"
              log_min_duration_statement: 1s
              log_statement: ddl
              max_connections: 100
              max_prepared_transactions: 150
              shared_preload_libraries: timescaledb,pg_stat_statements
              ssl: "on"
              ssl_cert_file: /etc/certificate/tls.crt
              ssl_key_file: /etc/certificate/tls.key
              tcp_keepalives_idle: 900
              tcp_keepalives_interval: 100
              temp_file_limit: 1GB
              timescaledb.passfile: ../.pgpass
              unix_socket_directories: /var/run/postgresql
              unix_socket_permissions: "0750"
              wal_level: hot_standby
              wal_log_hints: "on"
            use_pg_rewind: true
            use_slots: true
          retry_timeout: 10
          ttl: 30
        method: restore_or_initdb
        post_init: /etc/timescaledb/scripts/post_init.sh
        restore_or_initdb:
          command: |
            /etc/timescaledb/scripts/restore_or_initdb.sh --encoding=UTF8 --locale=C.UTF-8
          keep_existing_recovery_conf: true
      kubernetes:
        role_label: role
        scope_label: cluster-name
        use_endpoints: true
      log:
        level: WARNING
      postgresql:
        authentication:
          replication:
            username: standby
          superuser:
            username: postgres
        basebackup:
        - waldir: /var/lib/postgresql/wal/pg_wal
        callbacks:
          on_reload: /etc/timescaledb/scripts/patroni_callback.sh
          on_restart: /etc/timescaledb/scripts/patroni_callback.sh
          on_role_change: /etc/timescaledb/scripts/patroni_callback.sh
          on_start: /etc/timescaledb/scripts/patroni_callback.sh
          on_stop: /etc/timescaledb/scripts/patroni_callback.sh
        create_replica_methods:
        - pgbackrest
        - basebackup
        listen: 0.0.0.0:5432
        pg_hba:
        - local     all             postgres                              peer
        - local     all             all                                   md5
        - hostnossl all,replication all                all                reject
        - hostssl   all             all                127.0.0.1/32       md5
        - hostssl   all             all                ::1/128            md5
        - hostssl   replication     standby            all                md5
        - hostssl   all             all                all                md5
        pgbackrest:
          command: /etc/timescaledb/scripts/pgbackrest_restore.sh
          keep_data: true
          no_master: true
          no_params: true
        recovery_conf:
          restore_command: /etc/timescaledb/scripts/pgbackrest_archive_get.sh %f "%p"
        use_unix_socket: true
      restapi:
        listen: 0.0.0.0:8008
    persistentVolumes:
      data:
        accessModes:
        - ReadWriteOnce
        annotations: {}
        enabled: true
        mountPath: /var/lib/postgresql
        size: 150Gi
        subPath: ""
      wal:
        accessModes:
        - ReadWriteOnce
        annotations: {}
        enabled: true
        mountPath: /var/lib/postgresql/wal
        size: 20Gi
        subPath: ""
    pgBouncer:
      config:
        default_pool_size: 12
        max_client_conn: 500
        pool_mode: transaction
        server_reset_query: DISCARD ALL
      enabled: false
      pg_hba:
      - local     all postgres                   peer
      - host      all postgres,standby 0.0.0.0/0 reject
      - host      all postgres,standby ::0/0     reject
      - hostssl   all all              0.0.0.0/0 md5
      - hostssl   all all              ::0/0     md5
      - hostnossl all all              0.0.0.0/0 reject
      - hostnossl all all              ::0/0     reject
      port: 6432
    podAnnotations: {}
    podManagementPolicy: OrderedReady
    postInit:
    - configMap:
        name: custom-init-scripts
        optional: true
    - secret:
        name: custom-secret-scripts
        optional: true
    prometheus:
      enabled: false
      image:
        pullPolicy: Always
        repository: wrouesnel/postgres_exporter
        tag: v0.7.0
    rbac:
      create: true
    readinessProbe:
      enabled: true
      failureThreshold: 6
      initialDelaySeconds: 5
      periodSeconds: 30
      successThreshold: 1
      timeoutSeconds: 5
    replicaCount: 1
    replicaLoadBalancer:
      annotations:
        service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: "4000"
      enabled: false
      port: 5432
    resources: {}
    secretNames: {}
    serviceAccount:
      create: true
    sharedMemory:
      useMount: false
    timescaledbTune:
      args: {}
      enabled: true
    tolerations: []
    unsafe: true
  timescaledbExternal:
    db_uri: ""
    enabled: false

HOOKS:
---
# Source: sketchbench/charts/bullet/charts/hdfs/templates/tests/canary-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "my-sketchbench-canary"
  annotations:
    "helm.sh/hook": test-success
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
spec:
  containers:
  - name: my-sketchbench-canary
    image: "gradiant/hdfs:2.7.7"
    imagePullPolicy: "IfNotPresent"
    env:
      - name: MY_POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
    command:
    - bash
    - -c
    - |
      # configure data for hadoop container
      . /tmp/hadoop-config/bootstrap.sh || exit 1
      # try to create a folder in hdfs
      hdfs dfs -mkdir -p /test || exit 1
      hdfs dfs -mkdir /test/$MY_POD_NAME || exit 1
      hdfs fsck /test/$MY_POD_NAME | grep 'is HEALTHY' || exit 1
      hdfs dfs -rm -r -R -f /test/$MY_POD_NAME || exit 1
    volumeMounts:
        - name: hadoop-config
          mountPath: /tmp/hadoop-config
  volumes:
  - name: hadoop-config
    configMap:
          name: my-sketchbench-hdfs-hadoop      
  restartPolicy: Never
MANIFEST:
---
# Source: sketchbench/charts/bullet/charts/hdfs/templates/hdfs-dn-pdb.yaml
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: my-sketchbench-hdfs-datanode
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: datanode
    helm.sh/chart: hdfs-0.1.10
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-sketchbench"
    app.kubernetes.io/version: "2.7.7"
    app.kubernetes.io/part-of: hdfs
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: hdfs
      app.kubernetes.io/component: datanode
      app.kubernetes.io/instance: my-sketchbench
  minAvailable: 3
---
# Source: sketchbench/charts/bullet/charts/hdfs/templates/hdfs-nn-pdb.yaml
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: my-sketchbench-hdfs-namenode
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: namenode
    helm.sh/chart: hdfs-0.1.10
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-sketchbench"
    app.kubernetes.io/version: "2.7.7"
    app.kubernetes.io/part-of: hdfs
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: hdfs
      app.kubernetes.io/component: namenode
      app.kubernetes.io/instance: my-sketchbench
  minAvailable: 1
---
# Source: sketchbench/charts/bullet/charts/pubsub/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-sketchbench-pubsub
  labels:
    app.kubernetes.io/name: pubsub
    helm.sh/chart: pubsub-13.0.3
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: kafka
automountServiceAccountToken: true
---
# Source: sketchbench/charts/kafka/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-sketchbench-kafka
  labels:
    app.kubernetes.io/name: kafka
    helm.sh/chart: kafka-13.0.2
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: kafka
automountServiceAccountToken: true
---
# Source: sketchbench/charts/bullet/charts/spark/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-sketchbench-spark-secret
  labels:
    app.kubernetes.io/name: spark
    helm.sh/chart: spark-5.6.1
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
---
# Source: sketchbench/charts/bullet/charts/hdfs/templates/hadoop-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-sketchbench-hdfs-hadoop
  labels:
    app.kubernetes.io/name: hdfs
    helm.sh/chart: hdfs-0.1.10
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-sketchbench"
    app.kubernetes.io/version: "2.7.7"
    app.kubernetes.io/part-of: hdfs
data:
  bootstrap.sh: |-
    #!/bin/bash
    
    : ${HADOOP_HOME:=/usr/local/hadoop}
    
    . $HADOOP_HOME/etc/hadoop/hadoop-env.sh
    
    # Directory to find config artifacts
    CONFIG_DIR="/tmp/hadoop-config"
    
    # Copy config files from volume mount
    
    for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
        if [[ -e ${CONFIG_DIR}/$f ]]; then
        cp ${CONFIG_DIR}/$f $HADOOP_HOME/etc/hadoop/$f
        else
        echo "ERROR: Could not find $f in $CONFIG_DIR"
        exit 1
        fi
    done
    
    # installing libraries if any - (resource urls added comma separated to the ACP system variable)
    cd $HADOOP_HOME/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -
    if [[ $2 == "namenode" ]]; then
        if [ ! -d "/dfs/name" ]; then
        mkdir -p /dfs/name
        $HADOOP_HOME/bin/hdfs namenode -format -force -nonInteractive
        fi
        $HADOOP_HOME/sbin/hadoop-daemon.sh start namenode
    fi
    if [[ $2 == "datanode" ]]; then
        if [ ! -d "/dfs/data" ]; then
        mkdir -p /dfs/data
        fi
        #  wait up to 30 seconds for namenode
        (while [[ $count -lt 15 && -z `curl -sf http://my-sketchbench-hdfs-namenode:50070` ]]; do ((count=count+1)) ; echo "Waiting for my-sketchbench-hdfs-namenode" ; sleep 2; done && [[ $count -lt 15 ]])
        [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs namenode, exiting." && exit 1
    
        $HADOOP_HOME/sbin/hadoop-daemon.sh start datanode
    fi
    if [[ $1 == "-d" ]]; then
        until find ${HADOOP_HOME}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
        tail -F ${HADOOP_HOME}/logs/* &
        while true; do sleep 1000; done
    fi
    
    if [[ $1 == "-bash" ]]; then
        /bin/bash
    fi
  core-site.xml: |-
    <?xml version="1.0"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
        <property><name>fs.defaultFS</name><value>hdfs://my-sketchbench-hdfs-namenode:8020/</value></property>
        <property><name>hadoop.proxyuser.hdfs.hosts</name>
                <value>*</value>
        </property>
        <property>
            <name>hadoop.proxyuser.hdfs.groups</name>
            <value>*</value>
        </property>
    </configuration>
  hdfs-site.xml: |-
    <?xml version="1.0"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
        <property><name>dfs.datanode.use.datanode.hostname</name><value>false</value></property>
        <property><name>dfs.client.use.datanode.hostname</name><value>false</value></property>
        <property><name>dfs.datanode.data.dir</name><value>file:///dfs/data</value>
        <description>DataNode directory</description>
        </property>
    
        <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///dfs/name</value>
        <description>NameNode directory for namespace and transaction logs storage.</description>
        </property>
    
        <property>
        <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
        <value>false</value>
        </property>
    
        <!-- Bind to all interfaces -->
        <property>
        <name>dfs.namenode.rpc-bind-host</name>
        <value>0.0.0.0</value>
        </property>
        <property>
        <name>dfs.namenode.servicerpc-bind-host</name>
        <value>0.0.0.0</value>
        </property>
        <!-- /Bind to all interfaces -->
        <property><name>dfs.replication</name><value>3</value></property>
    
    </configuration>
  mapred-site.xml: |-
    <?xml version="1.0"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
    </configuration>
  yarn-site.xml: |-
    <?xml version="1.0"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
    </configuration>
  httpfs-site.xml: |-
    <?xml version="1.0"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
    </configuration>
  httpfs-signature.secret: |-
    hadoop httpfs secret
  slaves: |
    localhost
---
# Source: sketchbench/charts/bullet/charts/hdfs/templates/hdfs-nn-exporter-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-sketchbench-hdfs-namenode-exporter
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: namenode
    helm.sh/chart: hdfs-0.1.10
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-sketchbench"
    app.kubernetes.io/version: "2.7.7"
    app.kubernetes.io/part-of: hdfs
data:
  config-exporter.yml: |-
    fsImagePath : '/dfs/name/current'
    skipPreviouslyParsed : true
    skipFileDistributionForGroupStats : false
    skipFileDistributionForUserStats : false
    skipFileDistributionForPathStats : false
    skipFileDistributionForPathSetStats : false
    fileSizeDistributionBuckets: ['0','1MiB', '32MiB', '64MiB', '128MiB', '1GiB', '10GiB']
---
# Source: sketchbench/charts/bullet/charts/pubsub/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-sketchbench-pubsub-scripts
  labels:
    app.kubernetes.io/name: pubsub
    helm.sh/chart: pubsub-13.0.3
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
data:
  setup.sh: |-
    #!/bin/bash

    ID="${MY_POD_NAME#"my-sketchbench-pubsub-"}"
    if [[ -f "/bitnami/kafka/data/meta.properties" ]]; then
        export KAFKA_CFG_BROKER_ID="$(grep "broker.id" /bitnami/kafka/data/meta.properties | awk -F '=' '{print $2}')"
    else
        export KAFKA_CFG_BROKER_ID="$((ID + 0))"
    fi

    exec /entrypoint.sh /run.sh
---
# Source: sketchbench/charts/bullet/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-sketchbench-bullet
  labels:
    helm.sh/chart: bullet-0.1.1
    app.kubernetes.io/name: bullet
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/version: "1.0.4"
    app.kubernetes.io/managed-by: Helm
data:
  bullet_ui_env_settings.json: |-
    {
      "default": {
        "queryHost": "http://localhost:9999",
        "queryNamespace": "api/bullet/queries",
        "queryPath": "ws-query",
        "validationPath": "validate-query",
        "queryStompRequestChannel": "/server/request",
        "queryStompResponseChannel": "/client/response",
        "schemaHost": "http://localhost:9999",
        "schemaNamespace": "api/bullet",
        "helpLinks": [
          {
            "name": "Tutorials",
            "link": "https://bullet-db.github.io/ui/usage"
          }
        ],
        "bugLink": "https://github.com/bullet-db/bullet-ui/issues",
        "modelVersion": 4,
        "migrations": {
          "deletions": "query"
        },
        "defaultValues": {
          "aggregationMaxSize": 1024,
          "rawMaxSize": 500,
          "durationMaxSecs": 9007199254740,
          "distributionNumberOfPoints": 11,
          "distributionQuantilePoints": "0, 0.25, 0.5, 0.75, 0.9, 1",
          "distributionQuantileStart": 0,
          "distributionQuantileEnd": 1,
          "distributionQuantileIncrement": 0.1,
          "windowEmitFrequencyMinSecs": 1,
          "everyForRecordBasedWindow": 1,
          "everyForTimeBasedWindow": 2000,
          "sketches": {
            "countDistinctMaxEntries": 16384,
            "groupByMaxEntries": 512,
            "distributionMaxEntries": 1024,
            "distributionMaxNumberOfPoints": 200,
            "topKMaxEntries": 1024,
            "topKErrorType": "No False Negatives"
          },
          "metadataKeyMapping": {
            "querySection": "Query",
            "windowSection": "Window",
            "sketchSection": "Sketch",
            "theta": "Theta",
            "uniquesEstimate": "Uniques Estimate",
            "queryCreationTime": "Receive Time",
            "queryTerminationTime": "Finish Time",
            "estimatedResult": "Was Estimated",
            "standardDeviations": "Standard Deviations",
            "normalizedRankError": "Normalized Rank Error",
            "maximumCountError": "Maximum Count Error",
            "itemsSeen": "Items Seen",
            "minimumValue": "Minimum Value",
            "maximumValue": "Maximum Value",
            "windowNumber": "Number",
            "windowSize": "Size",
            "windowEmitTime": "Emit Time",
            "expectedEmitTime": "Expected Emit Time"
          }
        }
      }
    }
  bullet_webservice_pubsub_config.yaml: |-
    bullet.pubsub.context.name: "QUERY_SUBMISSION"
    bullet.pubsub.class.name: "com.yahoo.bullet.kafka.KafkaPubSub"
    bullet.pubsub.kafka.bootstrap.servers: "my-sketchbench-pubsub:9092"
    bullet.pubsub.kafka.request.topic.name: "bullet.requests"
    bullet.pubsub.kafka.response.topic.name: "bullet.responses"
    bullet.pubsub.message.serde.class.name: "com.yahoo.bullet.pubsub.IdentityPubSubMessageSerDe"
  bullet_webservice_query_config.yaml: |-
    bullet.query.aggregation.max.size: 1024
  bullet_webservice_schema.json: |-
    [
        {
            "name": "probability",
            "type": "DOUBLE",
            "description": "Generated from Random#nextDouble"
        },
        {
            "name": "gaussian",
            "type": "DOUBLE",
            "description": "Generated from Random#nextGaussian"
        },
        {
            "name": "uuid",
            "type": "STRING",
            "description": "A UUID string generated from UUID#randomUUID"
        },
        {
            "name": "tuple_number",
            "type": "LONG",
            "description": "A numeric id for the tuple generated in a monotonically increasing fashion in this period"
        },
        {
            "name": "duration",
            "type": "LONG",
            "description": "A random number ranging from 0 to 10050 with a tendency to have a high frequency on lower values"
        },
        {
            "name": "type",
            "type": "STRING",
            "description": "A random string chosen from: foo, bar, baz, qux, quux, norf"
        },
        {
            "name": "subtypes",
            "type": "STRING_MAP",
            "description": "Contains two keys whose values are randomly chosen from: foo, bar, baz, qux, quux, norf",
            "subFields": [
                {"name": "field_A", "description": "Value randomly chosen from: foo, bar, baz, qux, quux, norf"},
                {"name": "field_B", "description": "Value randomly chosen from: foo, bar, baz, qux, quux, norf"}
            ]
        },
        {
            "name": "tags",
            "type": "BOOLEAN_MAP",
            "description": "Contains four keys which are four fragments of the uuid. The values are randomly generated boolean values from Random#nextBoolean"
        },
        {
            "name": "stats",
            "type": "LONG_MAP",
            "description": "This map contains some numeric information such as the current number of periods etc.",
            "subFields": [
                {"name": "period_count", "description": "The period in which this record was generated"},
                {"name": "record_number", "description": "A monotonically increasing id for the record. There may be gaps in the id but if the data generation has kept up with your maximum tuples per period, this is the nth tuple generated"},
                {"name": "timestamp", "description": "The ms time when this record was generated"},
                {"name": "nano_time", "description": "The ns time when this record was generated"}
            ]
        },
        {
            "name": "classifiers",
            "type": "STRING_MAP_LIST",
            "description": "This contains two maps, each with: field_A and field_B whose values are randomly chosen from: foo, bar, baz, qux, quux, norf"
        }
    ]
  bullet_spark_settings.yaml: |-
    ########################################################################################################################
    ################################################  Bullet Spark config ##################################################
    ########################################################################################################################
    # This is the name of the concrete implementation of Data Producer to use.
    bullet.spark.data.producer.class.name: "com.yahoo.bullet.spark.examples.RandomProducer"

    # If true, enables the Bullet DSL data producer which can be configured to read from a custom data source. If enabled,
    # the DSL data producer is used instead of the producer provided above. (See https://github.com/bullet-db/bullet-dsl)
    bullet.spark.dsl.data.producer.enable: true

    # If true, enables the deserializer between the Bullet DSL connector and converter components. Otherwise, this step is
    # skipped.
    bullet.spark.dsl.deserializer.enable: false

    # This is the batch interval of your Spark Streaming job. Find out more at
    # https://spark.apache.org/docs/latest/streaming-programming-guide.html#setting-the-right-batch-interval.
    bullet.spark.batch.duration.ms: 1000

    # This is the size of the buffer for accumulating queries in the Query Receiver before emitting to Spark.
    bullet.spark.receiver.query.block.size: 1

    # This is the maximum number of partitions that will be created by the Query Receiver.
    bullet.spark.receiver.query.coalesce.partitions: 10

    # This is the number of Data Producers.
    bullet.spark.data.producer.parallelism: 1

    # This is the checkpoint directory. If you are running your Spark on a cluster, the directory must be an HDFS path.
    bullet.spark.checkpoint.dir: "hdfs://my-sketchbench-hdfs:8020/spark/checkpoints"

    # If true, Bullet Spark recovers context from checkpoint files when restarting.
    # Otherwise Bullet Spark creates a new context.
    bullet.spark.recover.from.checkpoint.enable: false

    # This is the Spark application name.
    bullet.spark.app.name: "BulletSparkStreamingJob"

    # If true, Bullet Spark collects metrics which can be accessed via the Spark REST API (/metrics/json).
    bullet.spark.metrics.enabled: false

    # If true, enables parallel processing of queries in each partition of the Filter Streaming job, This is particularly
    # useful when using Producers that are Direct (e.g. DirectKafkaProducer) and you would like to avoid repartitioning
    # the data and instead choose to parallelize within each partition (fixed by the producer) instead.
    # It speeds up the processing within those partitions by partitioning queries to multiple threads to do the filtering
    # operation concurrently.
    bullet.spark.filter.partition.parallel.mode.enabled: false

    # This is the thread pool size to use when bullet.spark.filter.partition.parallel.mode.enabled is true.
    bullet.spark.filter.partition.parallel.mode.parallelism: 4

    # This is the minimum number of queries at which the parallel partition filtering is applied. Since there are fixed
    # costs to manage a thread pool, they are only created once the number of queries exceeds this threshold.
    # It is only used when bullet.spark.filter.partition.parallel.mode.enabled is true.
    bullet.spark.filter.partition.parallel.mode.min.query.threshold: 10

    # The following 2 settings are used to set the checkpoint intervals independently for each stateful transformation.
    # Checkpoint interval = Spark duration * checkpoint duration multiplier
    # Use this to control the frequency of checkpointing operation. If this is set too high, there might be too much
    # data to checkpoint (RDD lineage graph).
    bullet.spark.query.union.checkpoint.duration.multiplier: 10
    bullet.spark.join.checkpoint.duration.multiplier: 10

    # The feedback publisher switches your PubSub into QUERY_SUBMISSION mode to loop back metadata messages to query
    # receiver. If you need to change settings for your publisher in this mode that is different from the settings
    # used in the result publisher, override them here. This setting needs to be a Map if provided.
    # The example below pretends that your PubSub settings start with bullet.pubsub.custom. You will provide yours.
    # Example:
    #
    # bullet.spark.loop.pubsub.overrides:
    #   bullet.pubsub.custom.publisher.setting: 1
    #   bullet.pubsub.custom.nested.publisher.setting:
    #     foo: bar
    #     bar: baz
    bullet.spark.loop.pubsub.overrides: {}

    ########################################################################################################################
    ################################################ Spark Streaming config ################################################
    ########################################################################################################################
    # The following settings are passed to Spark directly. You can add more settings here.
    # Find out more information about configuring a Spark job at https://spark.apache.org/docs/latest/configuration.html.
    # Add configuration that change infrequently here and submit more variable settings while submitting the job on the
    # command line.
    spark.serializer: "org.apache.spark.serializer.KryoSerializer"
    spark.closure.serializer: "org.apache.spark.serializer.KryoSerializer"
    spark.streaming.stopGracefullyOnShutdown: "true"
    spark.streaming.receiver.writeAheadLog.enable: "false"
    spark.streaming.driver.writeAheadLog.allowBatching: "false"

    ########################################################################################################################
    ################################################ Query PubSub config ###################################################
    ########################################################################################################################
    # This is the type of PubSub context to use for result publisher.
    # The feedback publisher uses QUERY_SUBMISSION since it submits messages.
    bullet.pubsub.context.name: "QUERY_PROCESSING"
    # This is the name of the concrete implementation of PubSub to use.
    # By default, it is the bulletin REST in-memory PubSub.
    bullet.pubsub.class.name: "com.yahoo.bullet.kafka.KafkaPubSub"
    # Add settings specific to your PubSub.
    bullet.pubsub.kafka.bootstrap.servers: "my-sketchbench-pubsub:9092"
    bullet.pubsub.kafka.request.topic.name: "bullet.requests"
    bullet.pubsub.kafka.response.topic.name: "bullet.responses"
    bullet.pubsub.message.serde.class.name: "com.yahoo.bullet.pubsub.IdentityPubSubMessageSerDe"

    ########################################################################################################################
    ################################################ Bullet Core config ####################################################
    ########################################################################################################################
    ## You can also configure the core Bullet settings here. For documentation and defaults for those settings, refer to:
    ## https://github.com/bullet-db/bullet-core/blob/master/src/main/resources/bullet_defaults.yaml
    ########################################################################################################################
    ########################################################################################################################
    bullet.query.aggregation.raw.max.size: 500
    # This setting is enforced in the API at this time
    # bullet.query.aggregation.max.size: 1024
    bullet.query.aggregation.count.distinct.sketch.entries: 16384
    bullet.query.aggregation.group.sketch.entries: 1024
    bullet.query.aggregation.distribution.sketch.entries: 1024
    bullet.query.aggregation.distribution.max.points: 200
    bullet.query.aggregation.distribution.generated.points.rounding: 6
    bullet.query.aggregation.top.k.sketch.entries: 1024
    bullet.query.aggregation.top.k.sketch.error.type: "NFN"
    bullet.result.metadata.enable: true
    # Factory class to get new BulletRecords.
    bullet.record.provider.class.name: "com.yahoo.bullet.record.simple.UntypedSimpleBulletRecordProvider"
    ########################################################################################################################
    ################################################ Bullet DSL config #####################################################
    ########################################################################################################################
    ## For documentation and defaults for those settings, refer to:
    ## https://github.com/bullet-db/bullet-dsl/blob/master/src/main/resources/bullet_dsl_defaults.yaml
    ########################################################################################################################
    ########################################################################################################################
    # The classpath to the BulletConnector to use
    bullet.dsl.connector.class.name: "com.yahoo.bullet.dsl.connector.KafkaConnector"
    # The read timeout duration in ms (defaults to 0)
    bullet.dsl.connector.read.timeout.ms: 0
    # Whether or not to asynchronously commit messages (defaults to true)
    bullet.dsl.connector.async.commit.enable: true

    ###### KafkaConnector properties

    # The list of Kafka topics to subscribe to (required)
    bullet.dsl.connector.kafka.topics:
    - "sketchbench-test"
    # Whether or not the KafkaConsumer should seek to the end of its subscribed topics at initialization (defaults to false)
    bullet.dsl.connector.kafka.start.at.end.enable: false

    # Kafka properties (prefixed by "bullet.dsl.connector.kafka.") are passed to KafkaConsumer during construction with the
    # prefix removed. The properties below are required.
    # Properties found at: https://kafka.apache.org/20/javadoc/org/apache/kafka/clients/consumer/ConsumerConfig.html
    bullet.dsl.connector.kafka.bootstrap.servers: "my-sketchbench-kafka:9092"
    bullet.dsl.connector.kafka.group.id: "bullet-consumer-group"
    bullet.dsl.connector.kafka.key.deserializer: "org.apache.kafka.common.serialization.StringDeserializer"
    bullet.dsl.connector.kafka.value.deserializer: "org.apache.kafka.common.serialization.StringDeserializer"
    bullet.dsl.connector.kafka.enable.auto.commit: true

    ###### BulletRecordConverter properties

    # The classpath to the BulletRecordConverter to use
    bullet.dsl.converter.class.name: "com.yahoo.bullet.dsl.converter.JSONBulletRecordConverter"
    # The path to the schema file to use
    bullet.dsl.converter.schema.file: "/bullet/schemas/dsl_schema.json"
    # Should type checking be performed for fields with type in the schema. It is useful to make sure that the types in
    # your source records match your expectations. You can set this to false when you are sure of your schema. This is
    # ignored if you do not provide a schema.
    bullet.dsl.converter.schema.type.check.enable: false

    ###### BulletDeserializer properties

    # The classpath to the BulletDeserializer to use
    bullet.dsl.deserializer.class.name: "com.yahoo.bullet.dsl.deserializer.IdentityDeserializer"
  dsl_schema.json: |-
    {
      "fields": [
        {
          "name": "SketchBenchMessageID",
          "type": "INTEGER"
        },
        {
          "name": "SketchBenchBoolean",
          "type": "BOOLEAN"
        },
        {
          "name": "SketchBenchInteger",
          "type": "INTEGER"
        },
        {
          "name": "SketchBenchLong",
          "type": "LONG"
        },
        {
          "name": "SketchBenchFloat",
          "type": "FLOAT"
        },
        {
          "name": "SketchBenchDouble",
          "type": "DOUBLE"
        },
        {
          "name": "SketchBenchString",
          "type": "STRING"
        },
        {
          "name": "SketchBenchBooleanMap",
          "type": "BOOLEAN_MAP"
        },
        {
          "name": "SketchBenchIntegerMap",
          "type": "INTEGER_MAP"
        },
        {
          "name": "SketchBenchLongMap",
          "type": "LONG_MAP"
        },
        {
          "name": "SketchBenchFloatMap",
          "type": "FLOAT_MAP"
        },
        {
          "name": "SketchBenchDoubleMap",
          "type": "DOUBLE_MAP"
        },
        {
          "name": "SketchBenchStringMap",
          "type": "STRING_MAP"
        },
        {
          "name": "SketchBenchBooleanMapMap",
          "type": "BOOLEAN_MAP_MAP"
        },
        {
          "name": "SketchBenchIntegerMapMap",
          "type": "INTEGER_MAP_MAP"
        },
        {
          "name": "SketchBenchLongMapMap",
          "type": "LONG_MAP_MAP"
        },
        {
          "name": "SketchBenchFloatMapMap",
          "type": "FLOAT_MAP_MAP"
        },
        {
          "name": "SketchBenchDoubleMapMap",
          "type": "DOUBLE_MAP_MAP"
        },
        {
          "name": "SketchBenchStringMapMap",
          "type": "STRING_MAP_MAP"
        },
        {
          "name": "SketchBenchBooleanList",
          "type": "BOOLEAN_LIST"
        },
        {
          "name": "SketchBenchIntegerList",
          "type": "INTEGER_LIST"
        },
        {
          "name": "SketchBenchLongList",
          "type": "LONG_LIST"
        },
        {
          "name": "SketchBenchFloatList",
          "type": "FLOAT_LIST"
        },
        {
          "name": "SketchBenchDoubleList",
          "type": "DOUBLE_LIST"
        },
        {
          "name": "SketchBenchStringList",
          "type": "STRING_LIST"
        },
        {
          "name": "SketchBenchBooleanMapList",
          "type": "BOOLEAN_MAP_LIST"
        },
        {
          "name": "SketchBenchIntegerMapList",
          "type": "INTEGER_MAP_LIST"
        },
        {
          "name": "SketchBenchLongMapList",
          "type": "LONG_MAP_LIST"
        },
        {
          "name": "SketchBenchFloatMapList",
          "type": "FLOAT_MAP_LIST"
        },
        {
          "name": "SketchBenchDoubleMapList",
          "type": "DOUBLE_MAP_LIST"
        },
        {
          "name": "SketchBenchStringMapList",
          "type": "STRING_MAP_LIST"
        }
      ]
    }
---
# Source: sketchbench/charts/kafka/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-sketchbench-kafka-scripts
  labels:
    app.kubernetes.io/name: kafka
    helm.sh/chart: kafka-13.0.2
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
data:
  setup.sh: |-
    #!/bin/bash

    ID="${MY_POD_NAME#"my-sketchbench-kafka-"}"
    if [[ -f "/bitnami/kafka/data/meta.properties" ]]; then
        export KAFKA_CFG_BROKER_ID="$(grep "broker.id" /bitnami/kafka/data/meta.properties | awk -F '=' '{print $2}')"
    else
        export KAFKA_CFG_BROKER_ID="$((ID + 0))"
    fi

    exec /entrypoint.sh /run.sh
---
# Source: sketchbench/templates/data-ingestion-espbench-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-sketchbench-data-ingestion-espbench
  labels:
    helm.sh/chart: sketchbench-0.1.0
    app.kubernetes.io/name: sketchbench
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: data-ingestion-espbench
data:
  datasender.conf: |-
    kafka-producer-config.bootstrap-servers = "my-sketchbench-kafka:9092"
    kafka-producer-config.key-serializer-class = "org.apache.kafka.common.serialization.StringSerializer"
    kafka-producer-config.value-serializer-class = "org.apache.kafka.common.serialization.StringSerializer"
    kafka-producer-config.acks = 1
    kafka-producer-config.batch-size = 16384 # default value in bytes
    kafka-producer-config.buffer-memory-size = 33554432 # default value in bytes
    kafka-producer-config.linger-time = 0 # default value in milliseconds

    data-reader-config.data-input-path = ["/dataset/debs2012.txt"]
    data-reader-config.read-in-ram = false
    verbose = true

  commons.conf: |-
    topic-prefix = "SketchBench"
    benchmark-run = 1
    query-configs = [
        {
            name = "Identity"
            number-of-streams = 1
        }
    ]
    sending-interval = 10000
    sending-interval-time-unit = "NANOSECONDS" # Java Timeunit Enum
    duration = 5
    duration-time-unit = "MINUTES" # Java Timeunit Enum
    kafka-bootstrap-servers = "my-sketchbench-kafka:9092"
    zookeeper-servers = "my-sketchbench-kafka-zookeeper:2181"
---
# Source: sketchbench/charts/bullet/charts/hdfs/templates/hdfs-dn-svc-headless.yaml
# A headless service to create DNS records
apiVersion: v1
kind: Service
metadata:
  name: my-sketchbench-hdfs-datanode
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: datanode
    helm.sh/chart: hdfs-0.1.10
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-sketchbench"
    app.kubernetes.io/version: "2.7.7"
    app.kubernetes.io/part-of: hdfs
spec:
  ports:
  - name: webhdfs
    port: 50075
  clusterIP: None
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: datanode
    app.kubernetes.io/instance: my-sketchbench
---
# Source: sketchbench/charts/bullet/charts/hdfs/templates/hdfs-nn-exporter-service.yml
kind: Service
apiVersion: v1
metadata:
  name: my-sketchbench-hdfs-namenode-exporter
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: namenode
    helm.sh/chart: hdfs-0.1.10
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-sketchbench"
    app.kubernetes.io/version: "2.7.7"
    app.kubernetes.io/part-of: hdfs
spec: 
  selector:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: namenode
    app.kubernetes.io/instance: my-sketchbench
  ports:
  - port: 5556
    name: metrics
    targetPort: 5556
---
# Source: sketchbench/charts/bullet/charts/hdfs/templates/hdfs-nn-svc-headless.yaml
# A headless service to create DNS records
apiVersion: v1
kind: Service
metadata:
  name: my-sketchbench-hdfs-namenode
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: namenode
    helm.sh/chart: hdfs-0.1.10
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-sketchbench"
    app.kubernetes.io/version: "2.7.7"
    app.kubernetes.io/part-of: hdfs
spec:
  ports:
  - name: dfs
    port: 8020
    protocol: TCP
  - name: webhdfs
    port: 50070
  clusterIP: None
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: namenode
    app.kubernetes.io/instance: my-sketchbench
---
# Source: sketchbench/charts/bullet/charts/hdfs/templates/hdfs-nn-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-sketchbench-hdfs
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: namenode
    helm.sh/chart: hdfs-0.1.10
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-sketchbench"
    app.kubernetes.io/version: "2.7.7"
    app.kubernetes.io/part-of: hdfs
spec:
  ports:
  - name: dfs
    port: 8020
    protocol: TCP
  - name: webhdfs
    port: 50070
  selector:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: namenode
    app.kubernetes.io/instance: my-sketchbench
---
# Source: sketchbench/charts/bullet/charts/hdfs/templates/httpfs-svc.yaml
# A headless service to create DNS records
apiVersion: v1
kind: Service
metadata:
  name: my-sketchbench-hdfs-httpfs
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: httpfs
    helm.sh/chart: hdfs-0.1.10
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-sketchbench"
    app.kubernetes.io/version: "2.7.7"
    app.kubernetes.io/part-of: hdfs
spec:
  ports:
  - name: httpfs
    port: 14000
    protocol: TCP
  selector:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: httpfs
    app.kubernetes.io/instance: my-sketchbench
---
# Source: sketchbench/charts/bullet/charts/pubsub/charts/zookeeper/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-sketchbench-zookeeper-headless
  namespace: default
  labels:
    app.kubernetes.io/name: zookeeper
    helm.sh/chart: zookeeper-7.0.1
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    
    - name: tcp-client
      port: 2181
      targetPort: client
    
    
    - name: follower
      port: 2888
      targetPort: follower
    - name: tcp-election
      port: 3888
      targetPort: election
  selector:
    app.kubernetes.io/name: zookeeper
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/component: zookeeper
---
# Source: sketchbench/charts/bullet/charts/pubsub/charts/zookeeper/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-sketchbench-zookeeper
  namespace: default
  labels:
    app.kubernetes.io/name: zookeeper
    helm.sh/chart: zookeeper-7.0.1
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
spec:
  type: ClusterIP
  ports:
    
    - name: tcp-client
      port: 2181
      targetPort: client
      nodePort: null
    
    
    - name: follower
      port: 2888
      targetPort: follower
    - name: tcp-election
      port: 3888
      targetPort: election
  selector:
    app.kubernetes.io/name: zookeeper
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/component: zookeeper
---
# Source: sketchbench/charts/bullet/charts/pubsub/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-sketchbench-pubsub-headless
  labels:
    app.kubernetes.io/name: pubsub
    helm.sh/chart: pubsub-13.0.3
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: kafka
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: tcp-client
      port: 9092
      protocol: TCP
      targetPort: kafka-client
    - name: tcp-internal
      port: 9093
      protocol: TCP
      targetPort: kafka-internal
  selector:
    app.kubernetes.io/name: pubsub
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/component: kafka
---
# Source: sketchbench/charts/bullet/charts/pubsub/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-sketchbench-pubsub
  labels:
    app.kubernetes.io/name: pubsub
    helm.sh/chart: pubsub-13.0.3
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: kafka
spec:
  type: ClusterIP
  ports:
    - name: tcp-client
      port: 9092
      protocol: TCP
      targetPort: kafka-client
      nodePort: null
  selector:
    app.kubernetes.io/name: pubsub
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/component: kafka
---
# Source: sketchbench/charts/bullet/charts/pubsubMonit/templates/bundle.yaml
kind: Service
apiVersion: v1
metadata:
  name: my-sketchbench-pubsub-monit
  labels:
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/name: pubsub-monit
    app.kubernetes.io/version: 3.27.0
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 9000
      protocol: TCP
      targetPort: http
      nodePort: null
  selector:
    
    app.kubernetes.io/name: pubsub-monit
    app.kubernetes.io/instance: my-sketchbench
---
# Source: sketchbench/charts/bullet/charts/spark/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-sketchbench-spark-headless
  labels:
    app.kubernetes.io/name: spark
    helm.sh/chart: spark-5.6.1
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  clusterIP: None
  selector:
    app.kubernetes.io/name: spark
    app.kubernetes.io/instance: my-sketchbench
---
# Source: sketchbench/charts/bullet/charts/spark/templates/svc-master.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-sketchbench-spark-master-svc
  labels:
    app.kubernetes.io/name: spark
    helm.sh/chart: spark-5.6.1
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
  annotations:
spec:
  type: ClusterIP
  ports:
    - port: 7077
      targetPort: cluster
      name: cluster
      nodePort: null
    - port: 80
      targetPort: http
      name: http
      protocol: TCP
      nodePort: null
  selector:
    app.kubernetes.io/name: spark
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/component: master
---
# Source: sketchbench/charts/bullet/templates/spark-backend-service-driver.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-sketchbench-bullet-spark-backend-driver
  labels:
    helm.sh/chart: bullet-0.1.1
    app.kubernetes.io/name: bullet
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/version: "1.0.4"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: spark-backend
spec:
  selector:
    app.kubernetes.io/component: spark-backend
    app.kubernetes.io/name: bullet
    app.kubernetes.io/instance: my-sketchbench
  type: ClusterIP
  ports:
  - name: driver
    protocol: TCP
    port: 4041
    targetPort: 4041
  - name: block-manager
    protocol: TCP
    port: 4042
    targetPort: 4042
---
# Source: sketchbench/charts/bullet/templates/spark-backend-service-ui.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-sketchbench-bullet-spark-backend-ui
  labels:
    helm.sh/chart: bullet-0.1.1
    app.kubernetes.io/name: bullet
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/version: "1.0.4"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: spark-backend
spec:
  selector:
    app.kubernetes.io/component: spark-backend
    app.kubernetes.io/name: bullet
    app.kubernetes.io/instance: my-sketchbench
  type: ClusterIP
  ports:
  - name: spark-ui
    protocol: TCP
    port: 4040
    targetPort: 4040
---
# Source: sketchbench/charts/bullet/templates/ui-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-sketchbench-bullet-ui
  labels:
    helm.sh/chart: bullet-0.1.1
    app.kubernetes.io/name: bullet
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/version: "1.0.4"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: ui
spec:
  selector:
    app.kubernetes.io/component: ui
    app.kubernetes.io/name: bullet
    app.kubernetes.io/instance: my-sketchbench
  type: ClusterIP
  ports:
  - name: ui
    protocol: TCP
    port: 8800
    targetPort: 8800
---
# Source: sketchbench/charts/bullet/templates/web-service-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-sketchbench-bullet-web-service
  labels:
    helm.sh/chart: bullet-0.1.1
    app.kubernetes.io/name: bullet
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/version: "1.0.4"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: web-service
spec:
  selector:
    app.kubernetes.io/component: web-service
    app.kubernetes.io/name: bullet
    app.kubernetes.io/instance: my-sketchbench
  type: ClusterIP
  ports:
  - name: web-service
    protocol: TCP
    port: 9999
    targetPort: 9999
---
# Source: sketchbench/charts/kafdrop/templates/bundle.yaml
kind: Service
apiVersion: v1
metadata:
  name: my-sketchbench-kafka-monit
  labels:
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/name: kafka-monit
    app.kubernetes.io/version: 3.27.0
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 9000
      protocol: TCP
      targetPort: http
      nodePort: null
  selector:
    
    app.kubernetes.io/name: kafka-monit
    app.kubernetes.io/instance: my-sketchbench
---
# Source: sketchbench/charts/kafka/charts/zookeeper/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-sketchbench-kafka-zookeeper-headless
  namespace: default
  labels:
    app.kubernetes.io/name: kafka-zookeeper
    helm.sh/chart: zookeeper-7.0.1
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    
    - name: tcp-client
      port: 2181
      targetPort: client
    
    
    - name: follower
      port: 2888
      targetPort: follower
    - name: tcp-election
      port: 3888
      targetPort: election
  selector:
    app.kubernetes.io/name: kafka-zookeeper
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/component: zookeeper
---
# Source: sketchbench/charts/kafka/charts/zookeeper/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-sketchbench-kafka-zookeeper
  namespace: default
  labels:
    app.kubernetes.io/name: kafka-zookeeper
    helm.sh/chart: zookeeper-7.0.1
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
spec:
  type: ClusterIP
  ports:
    
    - name: tcp-client
      port: 2181
      targetPort: client
      nodePort: null
    
    
    - name: follower
      port: 2888
      targetPort: follower
    - name: tcp-election
      port: 3888
      targetPort: election
  selector:
    app.kubernetes.io/name: kafka-zookeeper
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/component: zookeeper
---
# Source: sketchbench/charts/kafka/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-sketchbench-kafka-headless
  labels:
    app.kubernetes.io/name: kafka
    helm.sh/chart: kafka-13.0.2
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: kafka
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: tcp-client
      port: 9092
      protocol: TCP
      targetPort: kafka-client
    - name: tcp-internal
      port: 9093
      protocol: TCP
      targetPort: kafka-internal
  selector:
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/component: kafka
---
# Source: sketchbench/charts/kafka/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-sketchbench-kafka
  labels:
    app.kubernetes.io/name: kafka
    helm.sh/chart: kafka-13.0.2
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: kafka
spec:
  type: ClusterIP
  ports:
    - name: tcp-client
      port: 9092
      protocol: TCP
      targetPort: kafka-client
      nodePort: null
  selector:
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/component: kafka
---
# Source: sketchbench/charts/bullet/charts/hdfs/templates/httpfs-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-sketchbench-hdfs-httpfs
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: httpfs
    helm.sh/chart: hdfs-0.1.10
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-sketchbench"
    app.kubernetes.io/version: "2.7.7"
    app.kubernetes.io/part-of: hdfs
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: hdfs
      app.kubernetes.io/component: httpfs
      app.kubernetes.io/instance: "my-sketchbench"
  template:
    metadata:
      labels:
        app.kubernetes.io/name: hdfs
        app.kubernetes.io/component: httpfs
        app.kubernetes.io/instance: "my-sketchbench"
    spec:
      containers:
      - name: httpfs
        image: "gradiant/hdfs:2.7.7"
        imagePullPolicy: "IfNotPresent"
        env:
          - name: HTTPFS_HTTP_PORT
            value: "14000"
          - name: HTTPFS_ADMIN_PORT
            value: "14001"
          - name: CATALINA_OPTS
            value: -Dhttpfs.admin.hostname=0.0.0.0
        command:
        - "/opt/hadoop/sbin/httpfs.sh"
        - "run"
        resources:
          limits:
            cpu: 1000m
            memory: 2048Mi
          requests:
            cpu: 10m
            memory: 256Mi
        #livenessProbe:
        #  httpGet:
        #    path: /
        #    port: 50070
        #  initialDelaySeconds: 10
        #  timeoutSeconds: 2
        volumeMounts:
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop
      volumes:
      - name: hadoop-config
        configMap:
          name: my-sketchbench-hdfs-hadoop
---
# Source: sketchbench/charts/bullet/charts/pubsubMonit/templates/bundle.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: my-sketchbench-pubsub-monit
  labels:
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/name: pubsub-monit
    app.kubernetes.io/version: 3.27.0
spec:
  replicas: 1
  selector:
    matchLabels:
      
      app.kubernetes.io/name: pubsub-monit
      app.kubernetes.io/instance: my-sketchbench
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: my-sketchbench
        app.kubernetes.io/name: pubsub-monit
      annotations:
        checksum/config: 3aac6bbf87d55a3f944ca1c92de5813352f32a9f1380f34a817dd3ff5fcc365a
    spec:
      serviceAccountName: default
      containers:
        -
          name: pubsub-monit
          image: docker.io/obsidiandynamics/kafdrop:3.27.0
          imagePullPolicy: 
          env:
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: POD_SERVICE_ACCOUNT
              valueFrom:
                fieldRef:
                  fieldPath: spec.serviceAccountName
            - name: "TZ"
              value: "America/Los_Angeles"
            - name: KAFKA_BROKERCONNECT
              value: my-sketchbench-pubsub:9092
            - name: JVM_OPTS
              value: -Xms128M -Xmx256M -Xss180K -XX:-TieredCompilation -XX:+UseStringDeduplication
                -noverify
            - name: SERVER_SERVLET_CONTEXT_PATH
              value: /
            - name: SERVER_PORT
              value: "9000"
            - name: CMD_ARGS
              value: ""
            - name: KAFKA_PROPERTIES_FILE
              value: kafka.properties
            - name: KAFKA_TRUSTSTORE_FILE
              value: kafka.truststore.jks
            - name: KAFKA_KEYSTORE_FILE
              value: kafka.keystore.jks
          livenessProbe: 
            httpGet:
              path: '/actuator/health'
              port: http
            initialDelaySeconds: 60
          readinessProbe: 
            httpGet:
              path: '/actuator/health'
              port: http
            initialDelaySeconds: 60
          ports:
            - containerPort: 9000
              name: http
              protocol: TCP
---
# Source: sketchbench/charts/bullet/templates/spark-backend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-sketchbench-bullet-spark-backend
  labels:
    helm.sh/chart: bullet-0.1.1
    app.kubernetes.io/name: bullet
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/version: "1.0.4"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: spark-backend
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: spark-backend
      app.kubernetes.io/name: bullet
      app.kubernetes.io/instance: my-sketchbench
  template:
    metadata:
      labels:
        app.kubernetes.io/component: spark-backend
        app.kubernetes.io/name: bullet
        app.kubernetes.io/instance: my-sketchbench
    spec:
      securityContext:
        {}
      containers:
        - name: spark-backend
          securityContext:
            {}
          image: "sketchbench/bullet-spark:1.0.4"
          imagePullPolicy: IfNotPresent
          env:
          - name: HADOOP_USER_NAME
            value: hdfs
          args:
            - spark-submit
            - --master
            # https://github.com/bitnami/charts/blob/master/bitnami/spark/templates/_helpers.tpl
            - spark://my-sketchbench-spark-master-svc:7077
            - --deploy-mode
            - client
            - --conf
            - spark.driver.host=my-sketchbench-bullet-spark-backend-driver
            - --conf
            - spark.driver.port=4041
            - --conf
            - spark.driver.blockManager.port=4042
            - --conf
            - spark.driver.bindAddress=0.0.0.0
            - --conf
            - spark.executor.cores=2
            - --conf
            - spark.executor.memory=3G
            - --class
            - com.yahoo.bullet.spark.BulletSparkStreamingMain
            - --jars
            - /opt/bitnami/spark/jars/bullet-kafka-fat.jar,/opt/bitnami/spark/jars/bullet-dsl.jar,/opt/bitnami/spark/jars/bullet-spark-example.jar
            - /opt/bitnami/spark/jars/bullet-spark-standalone.jar
            - --bullet-spark-conf
            - /bullet/configs/bullet_spark_settings.yaml
          ports:
            - name: spark-ui
              containerPort: 4040
              protocol: TCP
            - name: driver
              containerPort: 4041
              protocol: TCP
            - name: block-manager
              containerPort: 4042
              protocol: TCP
          livenessProbe:
            httpGet:
              port: 4040
              path: /
          readinessProbe:
            httpGet:
              port: 4040
              path: /
          resources:
            {}
          volumeMounts:
            - name: config
              mountPath: /bullet/configs/bullet_spark_settings.yaml
              subPath: bullet_spark_settings.yaml
            - name: config
              mountPath: /bullet/schemas/dsl_schema.json
              subPath: dsl_schema.json
      volumes:
      - name: config
        configMap:
          name: my-sketchbench-bullet
---
# Source: sketchbench/charts/bullet/templates/ui-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-sketchbench-bullet-ui
  labels:
    helm.sh/chart: bullet-0.1.1
    app.kubernetes.io/name: bullet
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/version: "1.0.4"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: ui
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: ui
      app.kubernetes.io/name: bullet
      app.kubernetes.io/instance: my-sketchbench
  template:
    metadata:
      labels:
        app.kubernetes.io/component: ui
        app.kubernetes.io/name: bullet
        app.kubernetes.io/instance: my-sketchbench
    spec:
      securityContext:
        {}
      containers:
        - name: ui
          securityContext:
            {}
          image: "sketchbench/bullet-ui:1.1.0"
          imagePullPolicy: IfNotPresent
          env:
          - name: PORT
            value: "8800"
          ports:
            - name: service
              containerPort: 8800
              protocol: TCP
          livenessProbe:
            httpGet:
              port: 8800
              path: /
          readinessProbe:
            httpGet:
              port: 8800
              path: /
          resources:
            {}
          volumeMounts:
            - name: config
              mountPath: /usr/local/var/bullet/ui/config/env-settings.json
              subPath: bullet_ui_env_settings.json
      volumes:
      - name: config
        configMap:
          name: my-sketchbench-bullet
          items:
          - key: bullet_ui_pubsub_config.yaml
            path: pubsub_config.yaml
          - key: bullet_ui_query_config.yaml
            path: query_config.yaml
          - key: bullet_ui_schema.json
            path: schema.json
      volumes:
      - name: config
        configMap:
          name: my-sketchbench-bullet
---
# Source: sketchbench/charts/bullet/templates/web-service-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-sketchbench-bullet-web-service
  labels:
    helm.sh/chart: bullet-0.1.1
    app.kubernetes.io/name: bullet
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/version: "1.0.4"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: web-service
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: web-service
      app.kubernetes.io/name: bullet
      app.kubernetes.io/instance: my-sketchbench
  template:
    metadata:
      labels:
        app.kubernetes.io/component: web-service
        app.kubernetes.io/name: bullet
        app.kubernetes.io/instance: my-sketchbench
    spec:
      securityContext:
        {}
      containers:
        - name: web-service
          securityContext:
            {}
          image: "sketchbench/bullet-service:1.1.0"
          imagePullPolicy: IfNotPresent
          args:
            - java
            - -Dloader.path=/usr/local/var/bullet/pubsub/bullet-kafka-fat.jar
            - -jar
            - bullet-service-embedded.jar
            - --bullet.pubsub.config=/bullet/configs/pubsub_config.yaml
            - --bullet.query.config=/bullet/configs/query_config.yaml
            - --bullet.schema.file=/bullet/configs/schema.json
            - --server.port=9999
          ports:
            - name: service
              containerPort: 9999
              protocol: TCP
          livenessProbe:
            httpGet:
              port: 9999
              path: /api/bullet/columns
          readinessProbe:
            httpGet:
              port: 9999
              path: /api/bullet/columns
          resources:
            {}
          volumeMounts:
            - name: config
              mountPath: /bullet/configs
      volumes:
      - name: config
        configMap:
          name: my-sketchbench-bullet
          items:
          - key: bullet_webservice_pubsub_config.yaml
            path: pubsub_config.yaml
          - key: bullet_webservice_query_config.yaml
            path: query_config.yaml
          - key: bullet_webservice_schema.json
            path: schema.json
---
# Source: sketchbench/charts/kafdrop/templates/bundle.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: my-sketchbench-kafka-monit
  labels:
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/name: kafka-monit
    app.kubernetes.io/version: 3.27.0
spec:
  replicas: 1
  selector:
    matchLabels:
      
      app.kubernetes.io/name: kafka-monit
      app.kubernetes.io/instance: my-sketchbench
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: my-sketchbench
        app.kubernetes.io/name: kafka-monit
      annotations:
        checksum/config: 520119baf2c87aa105c02423bdf044ea3f8bf32bb23873cfadad269d5dd579f6
    spec:
      serviceAccountName: default
      containers:
        -
          name: kafdrop
          image: docker.io/obsidiandynamics/kafdrop:3.27.0
          imagePullPolicy: 
          env:
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: POD_SERVICE_ACCOUNT
              valueFrom:
                fieldRef:
                  fieldPath: spec.serviceAccountName
            - name: "TZ"
              value: "America/Los_Angeles"
            - name: KAFKA_BROKERCONNECT
              value: my-sketchbench-kafka:9092
            - name: JVM_OPTS
              value: -Xms128M -Xmx256M -Xss180K -XX:-TieredCompilation -XX:+UseStringDeduplication
                -noverify
            - name: SERVER_SERVLET_CONTEXT_PATH
              value: /
            - name: SERVER_PORT
              value: "9000"
            - name: CMD_ARGS
              value: ""
            - name: KAFKA_PROPERTIES_FILE
              value: kafka.properties
            - name: KAFKA_TRUSTSTORE_FILE
              value: kafka.truststore.jks
            - name: KAFKA_KEYSTORE_FILE
              value: kafka.keystore.jks
          livenessProbe: 
            httpGet:
              path: '/actuator/health'
              port: http
            initialDelaySeconds: 60
          readinessProbe: 
            httpGet:
              path: '/actuator/health'
              port: http
            initialDelaySeconds: 60
          ports:
            - containerPort: 9000
              name: http
              protocol: TCP
---
# Source: sketchbench/templates/data-ingestion-tester-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-sketchbench-data-ingestion-tester
  labels:
    helm.sh/chart: sketchbench-0.1.0
    app.kubernetes.io/name: sketchbench
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: data-ingestion-tester
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: data-ingestion-tester
      app.kubernetes.io/name: sketchbench
      app.kubernetes.io/instance: my-sketchbench
  template:
    metadata:
      labels:
        app.kubernetes.io/component: data-ingestion-tester
        app.kubernetes.io/name: sketchbench
        app.kubernetes.io/instance: my-sketchbench
    spec:
      securityContext:
        {}
      containers:
        - name: data-ingestion-tester
          securityContext:
            {}
          image: "sketchbench/sketchbench-data-ingestion-tester:1.0.1"
          imagePullPolicy: IfNotPresent
          args:
            - poetry
            - run
            - sketchbench-data-ingestion-tester
            # https://github.com/SketchBench/sketchbench-data-ingestion-tester#usage
            - --server
            - "my-sketchbench-kafka:9092"
            - --topic
            - "sketchbench-test"
            - --number-messages
            - "0"
            - --max-waiting-time
            - "0.5"
          resources:
            {}
---
# Source: sketchbench/charts/bullet/charts/hdfs/templates/hdfs-dn-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-sketchbench-hdfs-datanode
  annotations:
    checksum/config: d2855ca099021f0a42e68eb6aab9c12e814ca7975c35f896592142b03a56574a
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: datanode
    helm.sh/chart: hdfs-0.1.10
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-sketchbench"
    app.kubernetes.io/version: "2.7.7"
    app.kubernetes.io/part-of: hdfs
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: hdfs
      app.kubernetes.io/component: datanode
      app.kubernetes.io/instance: "my-sketchbench"
  serviceName: my-sketchbench-hdfs-datanode
  replicas: 3
  template:
    metadata:
      labels:
        app.kubernetes.io/name: hdfs
        app.kubernetes.io/component: datanode
        app.kubernetes.io/instance: "my-sketchbench"
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 5
            podAffinityTerm:
              topologyKey: "kubernetes.io/hostname"
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: hdfs
                  app.kubernetes.io/component: datanode
                  helm.sh/chart: hdfs-0.1.10
                  app.kubernetes.io/managed-by: "Helm"
                  app.kubernetes.io/instance: "my-sketchbench"
                  app.kubernetes.io/version: "2.7.7"
                  app.kubernetes.io/part-of: hdfs
      securityContext:
        fsGroup: 114
      initContainers:
      - name: "chown"
        image: "gradiant/hdfs:2.7.7"
        imagePullPolicy: "IfNotPresent"
        command:
        - /bin/bash
        - -c
        - chown -R hdfs:hadoop /dfs &&
          chmod g+s /dfs
        securityContext:
          runAsUser: 0
        volumeMounts:
        - mountPath: /dfs
          name: dfs
      containers:
      - name: datanode
        image: "gradiant/hdfs:2.7.7"
        imagePullPolicy: "IfNotPresent"
        command:
           - "/bin/bash"
           - "/tmp/hadoop-config/bootstrap.sh"
           - "-d"
           - "datanode"
        resources:
          limits:
            cpu: 1000m
            memory: 2048Mi
          requests:
            cpu: 10m
            memory: 256Mi
        readinessProbe:
          httpGet:
            path: /
            port: 50075
          initialDelaySeconds: 5
          timeoutSeconds: 2
        livenessProbe:
          httpGet:
            path: /
            port: 50075
          initialDelaySeconds: 10
          timeoutSeconds: 2
        volumeMounts:
        - name: hadoop-config
          mountPath: /tmp/hadoop-config
        - name: dfs
          mountPath: /dfs
      volumes:
      - name: hadoop-config
        configMap:
          name: my-sketchbench-hdfs-hadoop
      - name: dfs
        emptyDir: {}
---
# Source: sketchbench/charts/bullet/charts/hdfs/templates/hdfs-nn-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-sketchbench-hdfs-namenode
  annotations:
    checksum/config: d2855ca099021f0a42e68eb6aab9c12e814ca7975c35f896592142b03a56574a
  labels:
    app.kubernetes.io/name: hdfs
    app.kubernetes.io/component: namenode
    helm.sh/chart: hdfs-0.1.10
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "my-sketchbench"
    app.kubernetes.io/version: "2.7.7"
    app.kubernetes.io/part-of: hdfs
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: hdfs
      app.kubernetes.io/component: namenode
      app.kubernetes.io/instance: "my-sketchbench"
  serviceName: my-sketchbench-hdfs-namenode  
  replicas: 1
  template:
    metadata:
      labels:
        app.kubernetes.io/name: hdfs
        app.kubernetes.io/component: namenode
        app.kubernetes.io/instance: "my-sketchbench"
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 5
            podAffinityTerm:
              topologyKey: "kubernetes.io/hostname"
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: hdfs
                  app.kubernetes.io/component: namenode
                  helm.sh/chart: hdfs-0.1.10
                  app.kubernetes.io/managed-by: "Helm"
                  app.kubernetes.io/instance: "my-sketchbench"
                  app.kubernetes.io/version: "2.7.7"
                  app.kubernetes.io/part-of: hdfs
      initContainers:
      - name: "chown"
        image: "gradiant/hdfs:2.7.7"
        imagePullPolicy: "IfNotPresent"
        command:
        - /bin/bash
        - -c
        - chown -R hdfs:hadoop /dfs &&
          chmod g+s /dfs
        securityContext:
          runAsUser: 0
        volumeMounts:
        - mountPath: /dfs
          name: dfs
      containers:
      - name: namenode
        image: "gradiant/hdfs:2.7.7"
        imagePullPolicy: "IfNotPresent"
        command:
        - "/bin/bash"
        - "/tmp/hadoop-config/bootstrap.sh"
        - "-d"
        - "namenode"
        resources:
          limits:
            cpu: 1000m
            memory: 2048Mi
          requests:
            cpu: 10m
            memory: 256Mi
        readinessProbe:
          httpGet:
            path: /
            port: 50070
          initialDelaySeconds: 5
          timeoutSeconds: 2
        livenessProbe:
          httpGet:
            path: /
            port: 50070
          initialDelaySeconds: 10
          timeoutSeconds: 2
        volumeMounts:
        - name: hadoop-config
          mountPath: /tmp/hadoop-config
        - name: dfs
          mountPath: /dfs
      - name: namenode-exporter
        image: "marcelmay/hadoop-hdfs-fsimage-exporter:1.2"
        command:
        - /bin/sh
        - -c
        - java $JAVA_OPTS -jar /opt/fsimage-exporter/fsimage-exporter.jar 0.0.0.0 "5556" /exporter/config-exporter.yml
        ports:
        - containerPort: 5556
        resources:
                    null
        volumeMounts:
        - name: hadoop-config
          mountPath: /tmp/hadoop-config
        - name: config-exporter
          mountPath: /exporter
        - name: dfs
          mountPath: /dfs
      volumes:
      - name: hadoop-config
        configMap:
          name: my-sketchbench-hdfs-hadoop
      - name: config-exporter
        configMap:
          name: my-sketchbench-hdfs-namenode-exporter
      - name: dfs
        emptyDir: {}
---
# Source: sketchbench/charts/bullet/charts/pubsub/charts/zookeeper/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-sketchbench-zookeeper
  namespace: default
  labels:
    app.kubernetes.io/name: zookeeper
    helm.sh/chart: zookeeper-7.0.1
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
    role: zookeeper
spec:
  serviceName: my-sketchbench-zookeeper-headless
  replicas: 1
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: zookeeper
      app.kubernetes.io/instance: my-sketchbench
      app.kubernetes.io/component: zookeeper
  template:
    metadata:
      name: my-sketchbench-zookeeper
      labels:
        app.kubernetes.io/name: zookeeper
        helm.sh/chart: zookeeper-7.0.1
        app.kubernetes.io/instance: my-sketchbench
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: zookeeper
    spec:
      
      serviceAccountName: default
      securityContext:
        fsGroup: 1001
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: zookeeper
                    app.kubernetes.io/instance: my-sketchbench
                    app.kubernetes.io/component: zookeeper
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      containers:
        - name: zookeeper
          image: docker.io/bitnami/zookeeper:3.7.0-debian-10-r68
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          command:
            - bash
            - -ec
            - |
                # Execute entrypoint as usual after obtaining ZOO_SERVER_ID
                # check ZOO_SERVER_ID in persistent volume via myid
                # if not present, set based on POD hostname
                if [[ -f "/bitnami/zookeeper/data/myid" ]]; then
                  export ZOO_SERVER_ID="$(cat /bitnami/zookeeper/data/myid)"
                else
                  HOSTNAME=`hostname -s`
                  if [[ $HOSTNAME =~ (.*)-([0-9]+)$ ]]; then
                    ORD=${BASH_REMATCH[2]}
                    export ZOO_SERVER_ID=$((ORD + 1 ))
                  else
                    echo "Failed to get index from hostname $HOST"
                    exit 1
                  fi
                fi
                exec /entrypoint.sh /run.sh
          resources:
            requests:
              cpu: 250m
              memory: 256Mi
          env:
            - name: ZOO_DATA_LOG_DIR
              value: ""
            - name: ZOO_PORT_NUMBER
              value: "2181"
            - name: ZOO_TICK_TIME
              value: "2000"
            - name: ZOO_INIT_LIMIT
              value: "10"
            - name: ZOO_SYNC_LIMIT
              value: "5"
            - name: ZOO_MAX_CLIENT_CNXNS
              value: "60"
            - name: ZOO_4LW_COMMANDS_WHITELIST
              value: "srvr, mntr, ruok"
            - name: ZOO_LISTEN_ALLIPS_ENABLED
              value: "no"
            - name: ZOO_AUTOPURGE_INTERVAL
              value: "0"
            - name: ZOO_AUTOPURGE_RETAIN_COUNT
              value: "3"
            - name: ZOO_MAX_SESSION_TIMEOUT
              value: "40000"
            - name: ZOO_SERVERS
              value: my-sketchbench-zookeeper-0.my-sketchbench-zookeeper-headless.default.svc.cluster.local:2888:3888::1 
            - name: ZOO_ENABLE_AUTH
              value: "no"
            - name: ZOO_HEAP_SIZE
              value: "1024"
            - name: ZOO_LOG_LEVEL
              value: "ERROR"
            - name: ALLOW_ANONYMOUS_LOGIN
              value: "yes"
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
          ports:
            - name: client
              containerPort: 2181
            - name: follower
              containerPort: 2888
            - name: election
              containerPort: 3888
          livenessProbe:
            exec:
              command: ['/bin/bash', '-c', 'echo "ruok" | timeout 2 nc -w 2 localhost 2181 | grep imok']
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            exec:
              command: ['/bin/bash', '-c', 'echo "ruok" | timeout 2 nc -w 2 localhost 2181 | grep imok']
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          volumeMounts:
            - name: data
              mountPath: /bitnami/zookeeper
      volumes:
  volumeClaimTemplates:
    - metadata:
        name: data
        annotations:
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: sketchbench/charts/bullet/charts/pubsub/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-sketchbench-pubsub
  labels:
    app.kubernetes.io/name: pubsub
    helm.sh/chart: pubsub-13.0.3
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: kafka
spec:
  podManagementPolicy: Parallel
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: pubsub
      app.kubernetes.io/instance: my-sketchbench
      app.kubernetes.io/component: kafka
  serviceName: my-sketchbench-pubsub-headless
  updateStrategy:
    type: "RollingUpdate"
  template:
    metadata:
      labels:
        app.kubernetes.io/name: pubsub
        helm.sh/chart: pubsub-13.0.3
        app.kubernetes.io/instance: my-sketchbench
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: kafka
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: pubsub
                    app.kubernetes.io/instance: my-sketchbench
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
      serviceAccountName: my-sketchbench-pubsub
      containers:
        - name: kafka
          image: docker.io/bitnami/kafka:2.8.0-debian-10-r43
          imagePullPolicy: "IfNotPresent"
          command:
            - /scripts/setup.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: KAFKA_CFG_ZOOKEEPER_CONNECT
              value: "my-sketchbench-zookeeper"
            - name: KAFKA_INTER_BROKER_LISTENER_NAME
              value: "INTERNAL"
            - name: KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP
              value: "INTERNAL:PLAINTEXT,CLIENT:PLAINTEXT"
            - name: KAFKA_CFG_LISTENERS
              value: "INTERNAL://:9093,CLIENT://:9092"
            - name: KAFKA_CFG_ADVERTISED_LISTENERS
              value: "INTERNAL://$(MY_POD_NAME).my-sketchbench-pubsub-headless.default.svc.cluster.local:9093,CLIENT://$(MY_POD_NAME).my-sketchbench-pubsub-headless.default.svc.cluster.local:9092"
            - name: ALLOW_PLAINTEXT_LISTENER
              value: "yes"
            - name: KAFKA_VOLUME_DIR
              value: "/bitnami/kafka"
            - name: KAFKA_LOG_DIR
              value: "/opt/bitnami/kafka/logs"
            - name: KAFKA_CFG_DELETE_TOPIC_ENABLE
              value: "false"
            - name: KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE
              value: "true"
            - name: KAFKA_HEAP_OPTS
              value: "-Xmx1024m -Xms1024m"
            - name: KAFKA_CFG_LOG_FLUSH_INTERVAL_MESSAGES
              value: "10000"
            - name: KAFKA_CFG_LOG_FLUSH_INTERVAL_MS
              value: "1000"
            - name: KAFKA_CFG_LOG_RETENTION_BYTES
              value: "1073741824"
            - name: KAFKA_CFG_LOG_RETENTION_CHECK_INTERVALS_MS
              value: "300000"
            - name: KAFKA_CFG_LOG_RETENTION_HOURS
              value: "168"
            - name: KAFKA_CFG_MESSAGE_MAX_BYTES
              value: "1000012"
            - name: KAFKA_CFG_LOG_SEGMENT_BYTES
              value: "1073741824"
            - name: KAFKA_CFG_LOG_DIRS
              value: "/bitnami/kafka/data"
            - name: KAFKA_CFG_DEFAULT_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR
              value: "1"
            - name: KAFKA_CFG_NUM_IO_THREADS
              value: "8"
            - name: KAFKA_CFG_NUM_NETWORK_THREADS
              value: "3"
            - name: KAFKA_CFG_NUM_PARTITIONS
              value: "1"
            - name: KAFKA_CFG_NUM_RECOVERY_THREADS_PER_DATA_DIR
              value: "1"
            - name: KAFKA_CFG_SOCKET_RECEIVE_BUFFER_BYTES
              value: "102400"
            - name: KAFKA_CFG_SOCKET_REQUEST_MAX_BYTES
              value: "104857600"
            - name: KAFKA_CFG_SOCKET_SEND_BUFFER_BYTES
              value: "102400"
            - name: KAFKA_CFG_ZOOKEEPER_CONNECTION_TIMEOUT_MS
              value: "6000"
          ports:
            - name: kafka-client
              containerPort: 9092
            - name: kafka-internal
              containerPort: 9093
          livenessProbe:
            tcpSocket:
              port: kafka-client
            initialDelaySeconds: 10
            timeoutSeconds: 5
            failureThreshold: 
            periodSeconds: 
            successThreshold: 
          readinessProbe:
            tcpSocket:
              port: kafka-client
            initialDelaySeconds: 5
            timeoutSeconds: 5
            failureThreshold: 6
            periodSeconds: 
            successThreshold: 
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: data
              mountPath: /bitnami/kafka
            - name: logs
              mountPath: /opt/bitnami/kafka/logs
            - name: scripts
              mountPath: /scripts/setup.sh
              subPath: setup.sh
      volumes:
        - name: scripts
          configMap:
            name: my-sketchbench-pubsub-scripts
            defaultMode: 0755
        - name: logs
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: sketchbench/charts/bullet/charts/spark/templates/statefulset-master.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-sketchbench-spark-master
  labels:
    app.kubernetes.io/name: spark
    helm.sh/chart: spark-5.6.1
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: master
spec:
  serviceName: my-sketchbench-spark-headless
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: spark
      app.kubernetes.io/instance: my-sketchbench
      app.kubernetes.io/component: master
  template:
    metadata:
      labels:
        app.kubernetes.io/name: spark
        helm.sh/chart: spark-5.6.1
        app.kubernetes.io/instance: my-sketchbench
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: master
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: spark
                    app.kubernetes.io/instance: my-sketchbench
                    app.kubernetes.io/component: master
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
        runAsGroup: 0
      containers:
        - name: spark-master
          image: docker.io/sketchbench/bullet-spark:1.0.4
          imagePullPolicy: "IfNotPresent"
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
            - name: cluster
              containerPort: 7077
          volumeMounts:
          env:
            - name: SPARK_MODE
              value: "master"
            - name: SPARK_DAEMON_MEMORY
              value: 
            - name: SPARK_MASTER_PORT
              value: "7077"
            - name: SPARK_MASTER_WEBUI_PORT
              value: "8080"
          livenessProbe:
            httpGet:
              path: /
              port: 8080
            initialDelaySeconds: 180
            periodSeconds: 20
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            httpGet:
              path: /
              port: 8080
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          resources:
            limits: {}
            requests: {}
      volumes:
---
# Source: sketchbench/charts/bullet/charts/spark/templates/statefulset-worker.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-sketchbench-spark-worker
  labels:
    app.kubernetes.io/name: spark
    helm.sh/chart: spark-5.6.1
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: worker
spec:
  serviceName: my-sketchbench-spark-headless
  replicas: 3
  podManagementPolicy: OrderedReady
  selector:
    matchLabels:
      app.kubernetes.io/name: spark
      app.kubernetes.io/instance: my-sketchbench
      app.kubernetes.io/component: worker
  template:
    metadata:
      labels:
        app.kubernetes.io/name: spark
        helm.sh/chart: spark-5.6.1
        app.kubernetes.io/instance: my-sketchbench
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: worker
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: spark
                    app.kubernetes.io/instance: my-sketchbench
                    app.kubernetes.io/component: worker
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
        runAsGroup: 0
      containers:
        - name: spark-worker
          image: docker.io/sketchbench/bullet-spark:1.0.4
          imagePullPolicy: "IfNotPresent"
          ports:
            - name: http
              containerPort: 8081
              protocol: TCP
          volumeMounts:
          env:
            - name: SPARK_MODE
              value: "worker"
            - name: BASH_DEBUG
              value: "0"
            - name: SPARK_DAEMON_MEMORY
              value: 
            ## There are some environment variables whose existence needs
            ## to be checked because Spark checks if they are null instead of an
            ## empty string
            - name: SPARK_WORKER_CORES
              value: "3"
            - name: SPARK_WORKER_WEBUI_PORT
              value: "8081"
            - name: SPARK_DAEMON_JAVA_OPTS
              value: 
            - name: SPARK_MASTER_URL
              value: spark://my-sketchbench-spark-master-svc:7077
            # If you use a custom properties file, it must be loaded using a ConfigMap
            - name: SPARK_WORKER_OPTS
              value: 
          livenessProbe:
            httpGet:
              path: /
              port: 8081
            initialDelaySeconds: 180
            periodSeconds: 20
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            httpGet:
              path: /
              port: 8081
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          resources:
            limits: {}
            requests: {}
      volumes:
---
# Source: sketchbench/charts/kafka/charts/zookeeper/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-sketchbench-kafka-zookeeper
  namespace: default
  labels:
    app.kubernetes.io/name: kafka-zookeeper
    helm.sh/chart: zookeeper-7.0.1
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
    role: zookeeper
spec:
  serviceName: my-sketchbench-kafka-zookeeper-headless
  replicas: 1
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: kafka-zookeeper
      app.kubernetes.io/instance: my-sketchbench
      app.kubernetes.io/component: zookeeper
  template:
    metadata:
      name: my-sketchbench-kafka-zookeeper
      labels:
        app.kubernetes.io/name: kafka-zookeeper
        helm.sh/chart: zookeeper-7.0.1
        app.kubernetes.io/instance: my-sketchbench
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: zookeeper
    spec:
      
      serviceAccountName: default
      securityContext:
        fsGroup: 1001
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: kafka-zookeeper
                    app.kubernetes.io/instance: my-sketchbench
                    app.kubernetes.io/component: zookeeper
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      containers:
        - name: zookeeper
          image: docker.io/bitnami/zookeeper:3.7.0-debian-10-r68
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          command:
            - bash
            - -ec
            - |
                # Execute entrypoint as usual after obtaining ZOO_SERVER_ID
                # check ZOO_SERVER_ID in persistent volume via myid
                # if not present, set based on POD hostname
                if [[ -f "/bitnami/zookeeper/data/myid" ]]; then
                  export ZOO_SERVER_ID="$(cat /bitnami/zookeeper/data/myid)"
                else
                  HOSTNAME=`hostname -s`
                  if [[ $HOSTNAME =~ (.*)-([0-9]+)$ ]]; then
                    ORD=${BASH_REMATCH[2]}
                    export ZOO_SERVER_ID=$((ORD + 1 ))
                  else
                    echo "Failed to get index from hostname $HOST"
                    exit 1
                  fi
                fi
                exec /entrypoint.sh /run.sh
          resources:
            requests:
              cpu: 250m
              memory: 256Mi
          env:
            - name: ZOO_DATA_LOG_DIR
              value: ""
            - name: ZOO_PORT_NUMBER
              value: "2181"
            - name: ZOO_TICK_TIME
              value: "2000"
            - name: ZOO_INIT_LIMIT
              value: "10"
            - name: ZOO_SYNC_LIMIT
              value: "5"
            - name: ZOO_MAX_CLIENT_CNXNS
              value: "60"
            - name: ZOO_4LW_COMMANDS_WHITELIST
              value: "srvr, mntr, ruok"
            - name: ZOO_LISTEN_ALLIPS_ENABLED
              value: "no"
            - name: ZOO_AUTOPURGE_INTERVAL
              value: "0"
            - name: ZOO_AUTOPURGE_RETAIN_COUNT
              value: "3"
            - name: ZOO_MAX_SESSION_TIMEOUT
              value: "40000"
            - name: ZOO_SERVERS
              value: my-sketchbench-kafka-zookeeper-0.my-sketchbench-kafka-zookeeper-headless.default.svc.cluster.local:2888:3888::1 
            - name: ZOO_ENABLE_AUTH
              value: "no"
            - name: ZOO_HEAP_SIZE
              value: "1024"
            - name: ZOO_LOG_LEVEL
              value: "ERROR"
            - name: ALLOW_ANONYMOUS_LOGIN
              value: "yes"
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
          ports:
            - name: client
              containerPort: 2181
            - name: follower
              containerPort: 2888
            - name: election
              containerPort: 3888
          livenessProbe:
            exec:
              command: ['/bin/bash', '-c', 'echo "ruok" | timeout 2 nc -w 2 localhost 2181 | grep imok']
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            exec:
              command: ['/bin/bash', '-c', 'echo "ruok" | timeout 2 nc -w 2 localhost 2181 | grep imok']
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          volumeMounts:
            - name: data
              mountPath: /bitnami/zookeeper
      volumes:
  volumeClaimTemplates:
    - metadata:
        name: data
        annotations:
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: sketchbench/charts/kafka/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-sketchbench-kafka
  labels:
    app.kubernetes.io/name: kafka
    helm.sh/chart: kafka-13.0.2
    app.kubernetes.io/instance: my-sketchbench
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: kafka
spec:
  podManagementPolicy: Parallel
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: kafka
      app.kubernetes.io/instance: my-sketchbench
      app.kubernetes.io/component: kafka
  serviceName: my-sketchbench-kafka-headless
  updateStrategy:
    type: "RollingUpdate"
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kafka
        helm.sh/chart: kafka-13.0.2
        app.kubernetes.io/instance: my-sketchbench
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: kafka
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: kafka
                    app.kubernetes.io/instance: my-sketchbench
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
      serviceAccountName: my-sketchbench-kafka
      containers:
        - name: kafka
          image: docker.io/bitnami/kafka:2.8.0-debian-10-r43
          imagePullPolicy: "IfNotPresent"
          command:
            - /scripts/setup.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: KAFKA_CFG_ZOOKEEPER_CONNECT
              value: "my-sketchbench-kafka-zookeeper"
            - name: KAFKA_INTER_BROKER_LISTENER_NAME
              value: "INTERNAL"
            - name: KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP
              value: "INTERNAL:PLAINTEXT,CLIENT:PLAINTEXT"
            - name: KAFKA_CFG_LISTENERS
              value: "INTERNAL://:9093,CLIENT://:9092"
            - name: KAFKA_CFG_ADVERTISED_LISTENERS
              value: "INTERNAL://$(MY_POD_NAME).my-sketchbench-kafka-headless.default.svc.cluster.local:9093,CLIENT://$(MY_POD_NAME).my-sketchbench-kafka-headless.default.svc.cluster.local:9092"
            - name: ALLOW_PLAINTEXT_LISTENER
              value: "yes"
            - name: KAFKA_VOLUME_DIR
              value: "/bitnami/kafka"
            - name: KAFKA_LOG_DIR
              value: "/opt/bitnami/kafka/logs"
            - name: KAFKA_CFG_DELETE_TOPIC_ENABLE
              value: "false"
            - name: KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE
              value: "true"
            - name: KAFKA_HEAP_OPTS
              value: "-Xmx1024m -Xms1024m"
            - name: KAFKA_CFG_LOG_FLUSH_INTERVAL_MESSAGES
              value: "10000"
            - name: KAFKA_CFG_LOG_FLUSH_INTERVAL_MS
              value: "1000"
            - name: KAFKA_CFG_LOG_RETENTION_BYTES
              value: "1073741824"
            - name: KAFKA_CFG_LOG_RETENTION_CHECK_INTERVALS_MS
              value: "300000"
            - name: KAFKA_CFG_LOG_RETENTION_HOURS
              value: "168"
            - name: KAFKA_CFG_MESSAGE_MAX_BYTES
              value: "1000012"
            - name: KAFKA_CFG_LOG_SEGMENT_BYTES
              value: "1073741824"
            - name: KAFKA_CFG_LOG_DIRS
              value: "/bitnami/kafka/data"
            - name: KAFKA_CFG_DEFAULT_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR
              value: "1"
            - name: KAFKA_CFG_NUM_IO_THREADS
              value: "8"
            - name: KAFKA_CFG_NUM_NETWORK_THREADS
              value: "3"
            - name: KAFKA_CFG_NUM_PARTITIONS
              value: "1"
            - name: KAFKA_CFG_NUM_RECOVERY_THREADS_PER_DATA_DIR
              value: "1"
            - name: KAFKA_CFG_SOCKET_RECEIVE_BUFFER_BYTES
              value: "102400"
            - name: KAFKA_CFG_SOCKET_REQUEST_MAX_BYTES
              value: "104857600"
            - name: KAFKA_CFG_SOCKET_SEND_BUFFER_BYTES
              value: "102400"
            - name: KAFKA_CFG_ZOOKEEPER_CONNECTION_TIMEOUT_MS
              value: "6000"
          ports:
            - name: kafka-client
              containerPort: 9092
            - name: kafka-internal
              containerPort: 9093
          livenessProbe:
            tcpSocket:
              port: kafka-client
            initialDelaySeconds: 10
            timeoutSeconds: 5
            failureThreshold: 
            periodSeconds: 
            successThreshold: 
          readinessProbe:
            tcpSocket:
              port: kafka-client
            initialDelaySeconds: 5
            timeoutSeconds: 5
            failureThreshold: 6
            periodSeconds: 
            successThreshold: 
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: data
              mountPath: /bitnami/kafka
            - name: logs
              mountPath: /opt/bitnami/kafka/logs
            - name: scripts
              mountPath: /scripts/setup.sh
              subPath: setup.sh
      volumes:
        - name: scripts
          configMap:
            name: my-sketchbench-kafka-scripts
            defaultMode: 0755
        - name: logs
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"

